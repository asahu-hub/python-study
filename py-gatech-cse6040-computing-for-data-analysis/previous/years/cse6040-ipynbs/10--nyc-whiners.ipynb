{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 6040, Fall 2015 [10]: A Large-Data Workflow\n",
    "\n",
    "This notebook derives from an [awesome demo by the makers of plot.ly](https://plot.ly/ipython-notebooks/big-data-analytics-with-pandas-and-sqlite/).\n",
    "\n",
    "In particular, this notebook starts with a large database of complaints filed by residents of New York City since 2010 via 311 calls. The full dataset is available at the [NYC open data portal](https://nycopendata.socrata.com/data). At about 6 GB and 10 million complaints, you can infer that a) you might not want to read it all into memory at once, and b) NYC residents are really whiny. (OK, maybe you should only make conclusion \"a\".) The notebook then combines the use of `sqlite`, `pandas`, and [`Plotly`](https://plot.ly/python/) to build _interactive_ visualizations. So it's a great way to exercise several of the things we've learned so far in our course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To complete this notebook, you'll need to get your environment set up. The basic steps are:\n",
    "\n",
    "1. Set up `plotly`.\n",
    "2. Download the sample dataset.\n",
    "\n",
    "**Set up `plotly`.** To do the interactive visualization part of this notebook, you'll need to install `plotly` and sign up for an online `plotly` account. From the command-line on your system, you can do this by running:\n",
    "\n",
    "    pip install plotly\n",
    "    \n",
    "From within this notebook, you might also be able to accomplish the same thing by running the following inside the notebook.\n",
    "\n",
    "> The following example is for a default Mac OS X install of Anaconda; you may need to edit it for other systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plotly` service requires access to their servers.\n",
    "\n",
    "To get started, you will need to sign up for a `plotly` account, if you haven't done so already, at:\n",
    "\n",
    "    https://plot.ly/\n",
    "\n",
    "It's free! Well, to the extent that any too-good-to-be-true web service is \"free.\"\n",
    "\n",
    "Once you've done that, figure out what your API key is by visiting:\n",
    "\n",
    "    https://plot.ly/settings/api\n",
    "\n",
    "Lastly, sign into the `plotly` servers from within your notebook as follows.\n",
    "\n",
    "> Please modify this code to use your own username and API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "py.sign_in ('USERNAME', 'APIKEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, as a quick test let's make a simple plot using the \"baby names\" data set from [Lab 8](http://nbviewer.ipython.org/github/rvuduc/cse6040-ipynbs/blob/master/08--pandas-seaborn.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Build a Pandas data frame\n",
    "names = ['Bob','Jessica','Mary','John','Mel']\n",
    "births = [968, 155, 77, 578, 973]\n",
    "BabyDataSet = zip (names, births)\n",
    "df = pd.DataFrame(data=BabyDataSet, columns=['Names', 'Births'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot, using `plotly`\n",
    "from plotly.graph_objs import Bar\n",
    "\n",
    "plot_data = [Bar (x=df.Names, y=df.Births)]\n",
    "py.iplot (plot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download a sample dataset.** Next, grab a copy of today's dataset, which is a small (~ 20%) subset of the full dataset:\n",
    "\n",
    "* [SQLite DB, ~ 257 MiB] http://cse6040.gatech.edu/fa15/NYC-311-2M.db\n",
    "    \n",
    "Connect to this database as you did in the [last lab](http://nbviewer.ipython.org/github/rvuduc/cse6040-ipynbs/blob/master/09--sqlite3.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQLite database filename\n",
    "DB_FILENAME = 'NYC-311-2M.db'\n",
    "\n",
    "# Connect\n",
    "import sqlite3 as db\n",
    "disk_engine = db.connect (DB_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview the data.** This sample database has just a single table, named `data`. Let's query it and see how long it takes to read. To carry out the query, we will use the SQL reader built into `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print (\"Reading ...\")\n",
    "start_time = time.time ()\n",
    "\n",
    "# Perform SQL query through the disk_engine connection.\n",
    "# The return value is a pandas data frame.\n",
    "df = pd.read_sql_query('SELECT * FROM data', disk_engine)\n",
    "\n",
    "elapsed_time = time.time () - start_time\n",
    "print (\"==> Took %g seconds.\" % elapsed_time)\n",
    "\n",
    "# Dump the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More SQL stuff\n",
    "\n",
    "**Partial queries: `LIMIT` clause.** The preceding command was overkill for what we wanted, which was just to preview the table. Instead, we could have used the `LIMIT` option to ask for just a few results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT *\n",
    "    FROM data\n",
    "    LIMIT 5\n",
    "'''\n",
    "start_time = time.time ()\n",
    "df = pd.read_sql_query(query, disk_engine)\n",
    "elapsed_time = time.time () - start_time\n",
    "print (\"==> LIMIT version took %g seconds.\" % elapsed_time)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set membership: `IN` operator.** Another common idiom is to ask for rows whose attributes fall within a set, for which you can use the `IN` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT ComplaintType, Descriptor, Agency\n",
    "    FROM data\n",
    "    WHERE Agency IN (\"NYPD\", \"DOB\")\n",
    "    LIMIT 10\n",
    "'''\n",
    "\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding unique values: `DISTINCT` qualifier.** Yet another common idiom is to ask for the unique values of some attribute, for which you can use the `DISTINCT` qualifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = 'SELECT DISTINCT City FROM data'\n",
    "df = pd.read_sql_query(query, disk_engine)\n",
    "\n",
    "print (\"Found %d unique cities. The first few are:\" % len (df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming columns: `AS` operator.** Sometimes you might want to rename a result column. For instance, the following query counts the number of complaints by \"Agency,\" using the `COUNT(*)` function and `GROUP BY` clause, which we discussed in an earlier lab. If you wish to refer to the counts column of the resulting data frame, you can give it a more \"friendly\" name using the `AS` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT Agency, COUNT(*) AS NumComplaints\n",
    "    FROM data\n",
    "    GROUP BY Agency\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordering results: `ORDER` clause.** You can also order the results. For instance, suppose we want to execute the previous query by number of complaints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT Agency, COUNT(*) as NumComplaints\n",
    "    FROM data\n",
    "    GROUP BY Agency\n",
    "    ORDER BY NumComplaints\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.tail ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above example prints the bottom (tail) of the data frame. You could have also asked for the query results in reverse (descending) order, by prefixing the `ORDER BY` attribute with a `-` (minus) symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT Agency, COUNT(*) as NumComplaints\n",
    "    FROM data\n",
    "    GROUP BY Agency\n",
    "    ORDER BY -NumComplaints\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we can plot all of this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot ([Bar (x=df.Agency, y=df.NumComplaints)],\n",
    "          filename='311/most common complaints by city')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Create a `pandas` data frame that shows the number of complaints for each type, in descending order. What is the most common type of complaint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Insert your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also visualize the result, as a bar chart showing complaint types on the x-axis and the number of complaints on the y-axis. If necessary, modify the `plotly` command below to pull the correct columns from your data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot({\n",
    "    'data': [Bar (x=df.ComplaintType, y=df.NumComplaints)],\n",
    "    'layout': { \n",
    "        'margin': {'b': 150}, # Make the bottom margin a bit bigger to handle the long text\n",
    "        'xaxis': {'tickangle': 40}} # Angle the labels a bit\n",
    "    }, filename='311/most common complaints by complaint type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Determine the Top 10 whiniest cities. (That is, the 10 cities with the largest numbers of complaints.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Insert your answer here\n",
    "query = '''\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head (10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You should notice two bits of funny behavior, namely, that cities are treated in a _case-sensitive_ manner and that `None` appears as a city. (Presumably this setting occurs when a complaint is non-localized or the city is not otherwise specified.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case-insensitive grouping: `COLLATE NOCASE`.** One way to carry out the preceding query in a case-insensitive way is to add a `COLLATE NOCASE` qualifier to the `GROUP BY` clause.\n",
    "\n",
    "Let's filter out the 'None' cases as well, while we are at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT City, COUNT(*) AS NumComplaints\n",
    "    FROM data\n",
    "    WHERE City <> 'None'\n",
    "    GROUP BY City COLLATE NOCASE\n",
    "    ORDER BY -NumComplaints\n",
    "    LIMIT 10\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brooklyn is NYC's whiniest city. I knew it!\n",
    "\n",
    "Lastly, for later use, let's save the names of just the top 7 cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOP_CITIES = df.head (7)['City']\n",
    "TOP_CITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple series in `plotly`\n",
    "\n",
    "Here is another example of how to use a query to extract data and then recombine the results into a plot.\n",
    "\n",
    "Suppose we want to look at the number of complaints by type _and_ by city.\n",
    "\n",
    "Furthermore, suppose we want to render these results as a bar chart with \"complaints\" along the x-axis and cumulative counts, as stacked bars, along the y-axis, where different bars correspond to different cities. The `plotly` package requires that we create a list of _traces_, where each trace is a series to plot.\n",
    "\n",
    "Here's how we might construct such a list of traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "\n",
    "for city in TOP_CITIES:\n",
    "    query = '''\n",
    "      SELECT ComplaintType, COUNT(*) as NumComplaints\n",
    "        FROM data\n",
    "        WHERE City = \"{}\" COLLATE NOCASE\n",
    "        GROUP BY ComplaintType\n",
    "        ORDER BY -NumComplaints\n",
    "    '''.format (city)\n",
    "    df = pd.read_sql_query (query, disk_engine)\n",
    "    \n",
    "    traces.append (Bar (x=df['ComplaintType'],\n",
    "                        y=df.NumComplaints, \n",
    "                        name=city.capitalize()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list, we can create the stacked bar chart accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plotly.graph_objs import Layout\n",
    "\n",
    "py.iplot({'data': traces,\n",
    "          'layout': Layout (barmode='stack',\n",
    "                            xaxis={'tickangle': 40},\n",
    "                            margin={'b': 150})},\n",
    "         filename='311/complaints by city stacked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You can also `click` on the legend entries to hide/show the traces. Click-and-drag to zoom in and shift-drag to pan.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Make a variation of the above stacked bar chart that shows, for each complaint type (x-axis), the _percentage_ of complaints attributed to each city.\n",
    "\n",
    "Your code should create a new list of traces, `norm_traces`, which the `plotly` code below can then render as the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot({'data': norm_traces, \n",
    "          'layout': Layout(\n",
    "                barmode='stack',\n",
    "                xaxis={'tickangle': 40, 'autorange': False, 'range': [-0.5, 16]},\n",
    "                yaxis={'title': 'Percent of Complaints by City'},\n",
    "                margin={'b': 150},\n",
    "                title='Relative Number of 311 Complaints by City')\n",
    "         }, filename='311/relative complaints by city', validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data, what would you conclude about the various areas of NY city?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: SQLite time series with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Filter SQLite rows with timestamp strings: `YYYY-MM-DD hh:mm:ss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT ComplaintType, CreatedDate, City\n",
    "    FROM data\n",
    "    WHERE CreatedDate < \"2015-09-15 23:59:59\"\n",
    "          AND CreatedDate > \"2015-09-15 00:00:00\"\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Pull out the hour unit from timestamps with `strftime`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT CreatedDate, STRFTIME ('%H', CreatedDate) AS Hour, ComplaintType\n",
    "    FROM data\n",
    "    LIMIT 5\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Count the number of complaints (rows) per hour with `STRFTIME`, `GROUP BY`, and `COUNT(*)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT\n",
    "      CreatedDate,\n",
    "      strftime ('%H', CreatedDate) as Hour,\n",
    "      COUNT (*) AS `Complaints per Hour`\n",
    "    FROM data\n",
    "    GROUP BY Hour\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot({\n",
    "    'data': [Bar (x=df['Hour'], y=df['Complaints per Hour'])],\n",
    "    'layout': Layout (xaxis={'title': 'Hour in Day'},\n",
    "                      yaxis={'title': 'Number of Complaints'})},\n",
    "         filename='311/complaints per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Filter noise complaints by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT CreatedDate,\n",
    "         STRFTIME ('%H', CreatedDate) AS Hour,\n",
    "         COUNT (*) AS `Complaints per Hour`\n",
    "    FROM data\n",
    "    WHERE ComplaintType LIKE '%Noise%'\n",
    "    GROUP BY Hour\n",
    "    ORDER BY -`Complaints per Hour`\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "display (df.head(n=2))\n",
    "\n",
    "py.iplot({\n",
    "    'data': [Bar(x=df['Hour'], y=df['Complaints per Hour'])],\n",
    "    'layout': Layout(xaxis={'title': 'Hour in Day'},\n",
    "                     yaxis={'title': 'Number of Complaints'},\n",
    "                     title='Number of Noise Complaints in NYC by Hour in Day'\n",
    "                    )}, filename='311/noise complaints per hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Segregate complaints by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "complaint_traces = {} # Each series in the graph will represent a complaint\n",
    "complaint_traces['Other'] = {}\n",
    "\n",
    "for hour in range(1, 24):\n",
    "    hour_str = '0'+str(hour) if hour < 10 else str(hour)\n",
    "    query = '''\n",
    "      SELECT CreatedDate,\n",
    "             ComplaintType,\n",
    "             STRFTIME ('%H', CreatedDate) AS Hour,\n",
    "             COUNT (*) AS NumComplaints\n",
    "        FROM data\n",
    "        WHERE Hour = \"{}\"\n",
    "        GROUP BY ComplaintType\n",
    "        ORDER BY -NumComplaints\n",
    "    '''.format (hour_str)\n",
    "    df = pd.read_sql_query (query, disk_engine)\n",
    "    \n",
    "    complaint_traces['Other'][hour] = sum (df.NumComplaints)\n",
    "    \n",
    "    # Grab the 7 most common complaints for that hour\n",
    "    for i in range(7):\n",
    "        complaint = df.get_value(i, 'ComplaintType')\n",
    "        count = df.get_value(i, 'NumComplaints')\n",
    "        complaint_traces['Other'][hour] -= count\n",
    "        if complaint in complaint_traces:\n",
    "            complaint_traces[complaint][hour] = count\n",
    "        else:\n",
    "            complaint_traces[complaint] = {hour: count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traces = []\n",
    "for complaint in complaint_traces:\n",
    "    traces.append({\n",
    "        'x': range(25),\n",
    "        'y': [complaint_traces[complaint].get(i, None) for i in range(25)],\n",
    "        'name': complaint,\n",
    "        'type': 'bar'\n",
    "    })\n",
    "\n",
    "py.iplot({\n",
    "    'data': traces, \n",
    "    'layout': {\n",
    "        'barmode': 'stack',\n",
    "        'xaxis': {'title': 'Hour in Day'},\n",
    "        'yaxis': {'title': 'Number of Complaints'},\n",
    "        'title': 'The 7 Most Common 311 Complaints by Hour in a Day'\n",
    "    }}, filename='311/most common complaints by hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aggregated time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a new column with timestamps rounded to the previous 15 minute interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minutes = 15\n",
    "seconds = minutes*60\n",
    "\n",
    "query = '''\n",
    "  SELECT CreatedDate,\n",
    "         DATETIME ((STRFTIME ('%s', CreatedDate) / {seconds}) * {seconds},\n",
    "                   'unixepoch')\n",
    "           AS Interval\n",
    "    FROM data\n",
    "    LIMIT 10\n",
    "'''.format (seconds=seconds)\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "display (df.head ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, `GROUP BY` that interval and `COUNT(*)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minutes = 15\n",
    "seconds = minutes*60\n",
    "\n",
    "query = '''\n",
    "  SELECT CreatedDate,\n",
    "         DATETIME ((STRFTIME ('%s', CreatedDate) / {seconds}) * {seconds},\n",
    "                   'unixepoch')\n",
    "           AS Interval,\n",
    "         COUNT (*) AS `Complaints / Interval`\n",
    "    FROM data\n",
    "    GROUP BY Interval\n",
    "    ORDER BY Interval\n",
    "    LIMIT 500\n",
    "'''.format (seconds=seconds)\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "\n",
    "display (df.head ())\n",
    "display (df.tail ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    {\n",
    "        'data': [{\n",
    "            'x': df.Interval,\n",
    "            'y': df['Complaints / Interval'],\n",
    "            'type': 'bar'\n",
    "        }],\n",
    "        'layout': {\n",
    "            'title': 'Number of 311 Complaints per 15 Minutes'\n",
    "        }\n",
    "}, filename='311/complaints per 15 minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hours = 24\n",
    "minutes = hours*60\n",
    "seconds = minutes*60\n",
    "\n",
    "query = '''\n",
    "  SELECT CreatedDate,\n",
    "         DATETIME ((STRFTIME ('%s', CreatedDate) / {seconds}) * {seconds},\n",
    "                   'unixepoch')\n",
    "           AS Interval,\n",
    "         COUNT (*) AS `Complaints / Interval`\n",
    "    FROM data\n",
    "    GROUP BY Interval\n",
    "    ORDER BY Interval\n",
    "    LIMIT 500\n",
    "'''.format (seconds=seconds)\n",
    "\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "py.iplot(\n",
    "    {\n",
    "        'data': [{\n",
    "            'x': df.Interval,\n",
    "            'y': df['Complaints / Interval'],\n",
    "            'type': 'bar'\n",
    "        }],\n",
    "        'layout': {\n",
    "            'title': 'Number of 311 Complaints per Day'\n",
    "        }\n",
    "}, filename='311/complaints per day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more\n",
    "\n",
    "- Find more open data sets on [Data.gov](https://data.gov) and [NYC Open Data](https://nycopendata.socrata.com)\n",
    "- Learn how to setup [MySql with Pandas and Plotly](http://moderndata.plot.ly/graph-data-from-mysql-database-in-python/)\n",
    "- Add [interactive widgets to IPython notebooks](http://moderndata.plot.ly/widgets-in-ipython-notebook-and-plotly/) for customized data exploration\n",
    "- Big data workflows with [HDF5 and Pandas](http://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas)\n",
    "- [Interactive graphing with Plotly](https://plot.ly/python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from IPython.core.display import HTML\n",
    "#import urllib2\n",
    "#HTML(urllib2.urlopen('https://raw.githubusercontent.com/plotly/python-user-guide/css-updates/custom.css').read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
