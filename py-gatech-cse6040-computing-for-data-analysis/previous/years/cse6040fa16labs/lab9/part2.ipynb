{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "# Important note!\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR_ID = \"\" # Please enter your GT login, e.g., \"rvuduc3\" or \"gtg911x\"\n",
    "COLLABORATORS = [] # list of strings of your collaborators' IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b11295002cc2b9549d6a2b01721b6701",
     "grade": true,
     "grade_id": "who__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_CHECK_ID = re.compile (r'''[a-zA-Z]+\\d+|[gG][tT][gG]\\d+[a-zA-Z]''')\n",
    "assert RE_CHECK_ID.match (YOUR_ID) is not None\n",
    "\n",
    "collab_check = [RE_CHECK_ID.match (i) is not None for i in COLLABORATORS]\n",
    "assert all (collab_check)\n",
    "\n",
    "del collab_check\n",
    "del RE_CHECK_ID\n",
    "del re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter / IPython version check.** The following code cell verifies that you are using the correct version of Jupyter/IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbation theory and condition numbers [10 points]\n",
    "\n",
    "Let's start by asking how \"hard\" it is to solve a given linear system, $Ax=b$. You will apply perturbation theory to answer this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intuition: Continuous functions of a single variable.** To build your intuition, consider the simple case of a scalar function in a single continuous variable, $y = f(x)$. Suppose the input is perturbed by some amount, $\\Delta x$. The output will also change by some amount, $\\Delta y$. How large is $\\Delta y$ relative to $\\Delta x$?\n",
    "\n",
    "Supposing $\\Delta x$ is sufficiently small, you can approximate the change in the output by a Taylor series expansion of $f(x + \\Delta x)$:\n",
    "\n",
    "$$\n",
    "  y + \\Delta y = f(x + \\Delta x) = f(x) + \\Delta x \\frac{df}{dx} + O(\\Delta x^2).\n",
    "$$\n",
    "\n",
    "Since $\\Delta x$ is assumed to be \"small,\" we can approximate this relation by\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "    y + \\Delta y & \\approx & f(x) + \\Delta x \\frac{df}{dx} \\\\\n",
    "        \\Delta y & \\approx & \\Delta x \\frac{df}{dx}.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "This result should not be surprising: the first derivative measures the sensitivity of changes in the output to changes in the input. We will give the derivative a special name: it is the _(absolute) condition number_. If it is very large in the vicinity of $x$, then even small changes to the input will result in large changes in the output. Put differently, a large condition number indicates that the problem is intrinsically sensitive, so we should expect it may be difficult to construct an accurate algorithm.\n",
    "\n",
    "In addition to the absolute condition number, we can define a _relative_ condition number for the problem of evaluating $f(x)$.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "                \\Delta y &  \\approx   & \\Delta x \\frac{df}{dx} \\\\\n",
    "                         & \\Downarrow & \\\\\n",
    "  \\frac{|\\Delta y|}{|y|} &  \\approx   & \\frac{|\\Delta x|}{|x|} \\cdot \\underbrace{\\frac{|df/dx| \\cdot |x|}{|f(x)|}}_{\\kappa_f(x)}.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Here, the underscored factor, defined to be $\\kappa_f(x)$, is the relative analogue of the absolute condition number. Again, its magnitude tells us whether the output is sensitive to the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perturbation theory for linear systems.** What if we perturb a linear system? How can we measure its sensitivity or \"intrinsic difficulty\" to solve?\n",
    "\n",
    "First, recall the following identities linear algebraic identities:\n",
    "\n",
    "* _Triangle inequality_: $\\|x + y\\|_2 \\leq \\|x\\|_2 + \\|y\\|_2$\n",
    "* _Norm of a matrix-vector product_: $\\|Ax\\|_2 \\leq \\|A\\|_F\\cdot\\|x\\|_2$\n",
    "* _Norm of matrix-matrix product_: $\\|AB\\|_F \\leq \\|A\\|_F\\cdot\\|B\\|_F$\n",
    "\n",
    "To simplify the notation a little, we will drop the \"$2$\" and \"$F$\" subscripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose all of $A$, $b$, and the eventual solution $x$ undergo additive perturbations, denoted by $A + \\Delta A$, $b + \\Delta b$, and $x + \\Delta x$, respectively. Then, subtracting the original system from the perturbed system, you would obtain the following.\n",
    "\n",
    "$$\n",
    "\\begin{array}{rrcll}\n",
    "   &         (A + \\Delta A)(x + \\Delta x) & = & b + \\Delta b & \\\\\n",
    "- [&                                   Ax & = & b & ] \\\\\n",
    "\\hline\n",
    "   & \\Delta A x + (A + \\Delta A) \\Delta x & = & \\Delta b & \\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look more closely at the perturbation, $\\Delta x$, of the solution. Let $\\hat{x} \\equiv x + \\Delta x$ be the perturbed solution. Then the above can be rewritten as,\n",
    "\n",
    "$$\\Delta x = A^{-1} \\left(\\Delta b - \\Delta A \\hat{x}\\right),$$\n",
    "\n",
    "where we have assumed that $A$ is invertible. (That won't be true for our overdetermined system, but let's not worry about that for the moment.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How large is $\\Delta x$? Let's use a norm to measure it and bound it using \n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "  \\|\\Delta x\\| &   =   & \\|A^{-1} \\left(\\Delta b - \\Delta A \\hat{x}\\right)\\| \\\\\n",
    "               &  \\leq & \\|A^{-1}\\|\\cdot\\left(\\|\\Delta b\\| + \\|\\Delta A\\|\\cdot\\|\\hat{x}\\|\\right).\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can rewrite this as follows:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rcl}\n",
    "  \\frac{\\|\\Delta x\\|}\n",
    "       {\\|\\hat{x}\\|}\n",
    "    & \\leq &\n",
    "    \\|A^{-1}\\| \\cdot \\|A\\| \\cdot \\left(\n",
    "                                   \\frac{\\|\\Delta A\\|}\n",
    "                                        {\\|A\\|}\n",
    "                                   +\n",
    "                                   \\frac{\\Delta b}\n",
    "                                        {\\|A\\| \\cdot \\|\\hat{x}\\|}\n",
    "                                 \\right).\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bound says that the relative error of the perturbed solution, compared to relative perturbations in $A$ and $b$, scales with the product, $\\|A^{-1}\\| \\cdot \\|A\\|$. This factor is the linear systems analogue of the condition number for evaluating the function $f(x)$! As such, we define\n",
    "\n",
    "$$\\kappa(A) \\equiv \\|A^{-1}\\| \\cdot \\|A\\|$$\n",
    "\n",
    "as the _condition number of $A$_ for solving linear systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What values of $\\kappa(A)$ are \"large?\" Generally, you want to compare $\\kappa(A)$ to $1/\\epsilon$, where $\\epsilon$ is _machine precision_, which is the [maximum relative error under rounding](https://sites.ualberta.ca/~kbeach/phys420_580_2010/docs/ACM-Goldberg.pdf). We may look more closely at floating-point representations later on, but for now, a good notional value for $\\epsilon$ is about $10^{-7}$ in single-precision and $10^{-15}$ in double-precision. (In Python, the default format for floating-point values is double-precision.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis explains why solving the normal equations directly could lead to computational problems. In particular, one can show that $\\kappa(X^T X) \\approx \\kappa(X)^2$, which means forming $X^T X$ explicitly may make the problem harder to solve by a large amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Let's look at some examples of conditioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, recall the data matrix from Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "VARIABLES = ['BP', 'Age', 'Weight', 'BSA', 'Dur', 'Pulse', 'Stress']\n",
    "df = pd.read_table ('bloodpress.txt', usecols=VARIABLES)\n",
    "\n",
    "RESPONSE = 'BP'\n",
    "PREDICTORS = ['Weight', 'BSA']\n",
    "\n",
    "y = df.as_matrix ([RESPONSE])\n",
    "m = len (y)\n",
    "\n",
    "X_initial = df.as_matrix (PREDICTORS)\n",
    "X = np.insert (X_initial, [0], [[1.]] * m, axis=1)\n",
    "\n",
    "print (\"X (first five rows):\\n\")\n",
    "print (X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (1 point). Use Numpy's condition number estimator, `np.linalg.cond()`, to estimate the condition numbers for a) $X$ and b) $X^T X$. Use the form of the condition number based on the two-norm. Store the results in `cond_X` and `cond_XTX`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "da3e9749393da8685ae3b3d8faeb734e",
     "grade": false,
     "grade_id": "cond",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "17e8beb282cca6fa749b134b18e8b7ab",
     "grade": true,
     "grade_id": "cond__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "display (Math (r'\\kappa(X) \\approx {:.0f}'.format (cond_X)))\n",
    "display (Math (r'\\kappa(X)^2 \\approx {:.0f}'.format (cond_X**2)))\n",
    "display (Math (r'\\kappa(X^T X) \\approx {:.0f}'.format (cond_XTX)))\n",
    "\n",
    "assert 1. <= cond_X <= 3e3\n",
    "assert 1. <= cond_XTX <= 6e6\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** Let's look at a system that is ill-conditioned and see what happens when we make a tiny perturbation to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([(1., 1000.),\n",
    "              (2.**(-10) + 2.**(-11), 1.)])\n",
    "\n",
    "print (\"A ==\\n\", A)\n",
    "print (\"\\ncond (A) == \", np.linalg.cond (A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Delta_A = np.array ([(0., 0.),\n",
    "                     (-2.**(-11), 0.)\n",
    "                    ])\n",
    "B = A + Delta_A\n",
    "\n",
    "print (\"B := A + dA ==\\n\", B)\n",
    "print (\"\\ncond (B) / cond (A) == \",\n",
    "      np.linalg.cond (B) / np.linalg.cond (A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = np.array([1., 1.])\n",
    "\n",
    "x_A = np.linalg.solve (A, b)\n",
    "print (\"x ~= A^(-1)*b == \", x_A)\n",
    "\n",
    "x_B = np.linalg.solve (B, b)\n",
    "print (\"x ~= B^(-1)*b == \", x_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example.** Here is another example, taken from [Trefethen and Bau (1997)](http://bookstore.siam.org/ot50/) with Python code by [Da Kuang (2014)](http://math.ucla.edu/~dakuang/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "m = 101\n",
    "\n",
    "t = np.linspace (0., 1., m)\n",
    "y = np.exp (np.sin (4*t))\n",
    "y /= 2006.787453080206\n",
    "\n",
    "plt.plot (t, y, 'o--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** (2 points). The following code creates a matrix, $X$, based on the data created above. Explain what approximately solving the system $X \\alpha \\approx y$ for the vector $\\alpha$ does, effectively, given $y$ as computed above (`y[0:m]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 15\n",
    "X = np.zeros ((m, n))\n",
    "\n",
    "for j in range (n):\n",
    "    X[:, j] = np.power (t, j)\n",
    "    \n",
    "print (\"Condition number of X: %g\" % np.linalg.cond (X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dcf95f2331fe77569cd85d7fa143cc1c",
     "grade": true,
     "grade_id": "explain_A",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** (2 points). Compute the solution to this problem by solving the normal equations. Store your solution in a vector `alpha1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "46dc01ff57eb0dc369de30727cc2cb11",
     "grade": false,
     "grade_id": "alpha1",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print (\"Your solution, alpha1:\")\n",
    "print (alpha1)\n",
    "\n",
    "plt.plot (t, y, '.', t, X.dot (alpha1), '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6dda60a2d49202cd25dfe23ee50706c2",
     "grade": true,
     "grade_id": "alpha1__test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "r1 = X.dot (alpha1) - y\n",
    "r1_norm2 = np.linalg.norm (r1, 2)**2\n",
    "\n",
    "plt.semilogy (t, np.abs (y/r1), '*--')\n",
    "\n",
    "print (\"\\nResidual two-norm squared:\")\n",
    "print (r1_norm2)\n",
    "assert r1_norm2 <= 1e-13\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy's built-in linear least squares solver uses a different algorithm. Compare its solution to the one computed by solving the normal equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha2 = np.linalg.lstsq (X, y)[0]\n",
    "\n",
    "print (\"Numpy's built-in linear least squares solver:\")\n",
    "print (alpha2)\n",
    "\n",
    "r2 = X.dot (alpha2) - y\n",
    "r2_norm2 = np.linalg.norm (r2, 2)**2\n",
    "\n",
    "print (\"\\nTwo-norm squared:\", r2_norm2)\n",
    "\n",
    "print (\"\\n|alpha1 ./ alpha2| ==\")\n",
    "print (alpha1 / alpha2)\n",
    "\n",
    "plt.plot (alpha1 / alpha2, '*--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Nearly collinear predictors.** Another more practical situation in which poor conditioning can arise in linear regression modeling is when you include two strongly correlated predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (2 points). Create an $m \\times 2$ data matrix `X` with two columns of nearly collinear predictors. That is, if $x_0$ and $x_1$ are the columns, then create these columns such that they are not identical but have a correlation coefficient close to 1.0 and a condition number that is at least $10^{16}$.\n",
    "\n",
    "> You can compute the correlation coefficient between two vectors `a` and `b` by using Numpy's built-in method, `np.corrcoef(a, b)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ce3efef6b3638406fc5e9971056792e4",
     "grade": false,
     "grade_id": "X_collinear",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "M = 10 # Number of rows\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "XTX = X.T.dot(X)\n",
    "print ('cond (X):', np.linalg.cond (X))\n",
    "print ('cond (X^T*X):', np.linalg.cond (XTX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ffeb5cb14833680bd9e491a2e4acecfa",
     "grade": true,
     "grade_id": "X_collinear_test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "corr_coef = np.corrcoef (X[:, 0], X[:, 1])[0, 1]\n",
    "print (\"Correlation coefficient: {:.15f}\".format (corr_coef))\n",
    "assert corr_coef >= 0.99\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "**Exercise 5** (1 point). Let $\\theta^T = (0.1, 0.1)$ be the true solution of this problem. Compute the corresponding right-hand side, $y = X \\theta$. Call your right-hand side vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2b30b298a61eff06dd4ba7eb0826d4b3",
     "grade": true,
     "grade_id": "normeq",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "theta_true = np.array ([[0.1], [0.1]])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (2 points). Solve this system $X \\theta = y$ using the normal equations method, given `y` but \"pretending\" that you do not know `theta_true`. Store your result as `theta_1`. How does it compare to `theta_true`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d509ba33ea91ef042e3eebfd85831484",
     "grade": true,
     "grade_id": "theta_neq",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print (theta_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** (1 point). Use Numpy's built-in least squares solver instead (`np.linalg.lstsq()`), storing its estimate as a vector `theta_2`. Does it give a better answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "eb1d7d3d3f3fc90aaa1995cfccd984af",
     "grade": true,
     "grade_id": "theta_builtin",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print (theta_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
