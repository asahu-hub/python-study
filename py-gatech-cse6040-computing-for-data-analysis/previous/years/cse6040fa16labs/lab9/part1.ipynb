{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "# Important note!\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR_ID = \"\" # Please enter your GT login, e.g., \"rvuduc3\" or \"gtg911x\"\n",
    "COLLABORATORS = [] # list of strings of your collaborators' IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b11295002cc2b9549d6a2b01721b6701",
     "grade": true,
     "grade_id": "who__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_CHECK_ID = re.compile (r'''[a-zA-Z]+\\d+|[gG][tT][gG]\\d+[a-zA-Z]''')\n",
    "assert RE_CHECK_ID.match (YOUR_ID) is not None\n",
    "\n",
    "collab_check = [RE_CHECK_ID.match (i) is not None for i in COLLABORATORS]\n",
    "assert all (collab_check)\n",
    "\n",
    "del collab_check\n",
    "del RE_CHECK_ID\n",
    "del re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter / IPython version check.** The following code cell verifies that you are using the correct version of Jupyter/IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Linear regression via least squares [13 points]\n",
    "\n",
    "Recall our motivation for solving linear systems, which came from the linear regression problem as introduced in [an earlier notebook](http://nbviewer.jupyter.org/github/rvuduc/cse6040fa16labs/blob/master/lab7/linalg-motivation.ipynb) and summarized below.\n",
    "\n",
    "> This notebook goes through a somewhat detailed derivation of the least squares solution to the linear regression problem. You may right ask, why bother with these details when there are canned libraries and numerical routines that do a lot of the heavy-lifting for you? There are three reasons.\n",
    ">\n",
    "> 1. It's helpful to have some deeper intuition for how one formalizes a mathematical problem and derives a computational solution, in case you ever encounter a problem that does not exactly fit what a canned library can do for you.\n",
    ">\n",
    "> 2. If you have ever used a statistical analysis package, it's likely you have encountered \"strange\" numerical errors or warnings. Knowing how problems are derived can help you understand what might have gone wrong. We will see an example below.\n",
    ">\n",
    "> 3. Because data analysis is undergoing a revolution of interest, it's likely that new problems and new models will not exactly fit the template of existing models. Therefore, it's possible you will need to derive a new model or know how to talk to someone who can derive one for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formalizing the optimization problem\n",
    "\n",
    "Your data consists of $m$ observations and $n+1$ variables. One of these variables is the _response_ variable, $y$, which you want to predict from the other $n$ variables, $\\{x_1, \\ldots, x_n\\}$ (note the numbering starts at 1). Suppose you wish to fit a _linear model_ of the following form to these data,\n",
    "\n",
    "$$y_i \\approx \\theta_0 + x_{i,1} \\theta_1 + x_{i,2} \\theta_2 + \\cdots + x_{i,n} \\theta_n,$$\n",
    "\n",
    "where $\\{\\theta_j | 0 \\leq j \\leq n\\}$ is the set of unknown coefficients. Your modeling task is to choose values for these coefficients that \"best fit\" the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can arrange the observations into a tibble like this one:\n",
    "\n",
    "|     y      | x<sub>0</sub> | x<sub>1</sub> | x<sub>2</sub> | $\\cdots$ | x<sub>n</sub> |\n",
    "|:----------:|:-------------:|:-------------:|:-------------:|:--------:|:-------------:|\n",
    "|   $y_0$    |      1.0      |   $x_{0,1}$   |   $x_{0,2}$   | $\\cdots$ |   $x_{0,n}$   |\n",
    "|   $y_1$    |      1.0      |   $x_{1,1}$   |   $x_{1,2}$   | $\\cdots$ |   $x_{1,n}$   |\n",
    "|   $y_2$    |      1.0      |   $x_{2,1}$   |   $x_{2,2}$   | $\\cdots$ |   $x_{2,n}$   |\n",
    "|  $\\vdots$  |   $\\vdots$    |   $\\vdots$    |   $\\vdots$    | $\\vdots$ |   $\\vdots$    |\n",
    "|  $y_{m-1}$ |      1.0      |  $x_{m-1,1}$  |  $x_{m-1,2}$  | $\\cdots$ |  $x_{m-1,n}$  |\n",
    "\n",
    "This tibble includes an extra dummy variable, $x_0$, whose entries are all equal to 1.0. Treating each variable as a column vector, the modeling tasks is to find the vector $\\theta^T \\equiv (\\theta_0, \\theta_1, \\ldots, \\theta_{n-1})$ such that\n",
    "\n",
    "$$y \\approx X \\theta,$$\n",
    "\n",
    "where $y$ is the vector of responses and $X$ is the $m \\times (n+1)$ matrix whose columns are the corresponding vectors, $x_0$, $x_1$, $\\ldots$, $x_n$. The matrix $X$ composed this way from the predictors is sometimes referred to as the _(input) data matrix_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how should you choose $\\theta$? Suppose you are given $\\theta$. One way to measure its quality is to look at the difference between $y$ and the _(model) prediction_, $X \\theta$. A natural way to measure that difference is to use some vector norm, like the 2-norm (here, squared):\n",
    "\n",
    "$$ \\|X \\theta - y\\|_2^2 \\equiv \\|r\\|_2^2,$$\n",
    "\n",
    "where $r \\equiv X \\theta - y$ is the _residual error vector_ or just _residual_ for this model. Each element of $r$ is the residual for a given observation; thus, using the two-norm means each difference is squared, thereby \"penalizing\" larger differences more than smaller ones.\n",
    "\n",
    "> The additional squaring of $\\|r\\|_2$ could be interpreted similarly, though in reality it is chosen to simplify the math. In particular, recall (or convince yourself) that $\\|r\\|_2^2 = r^T r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this error measure, we can now formalize our mathematical goal as an optimization problem: compute the $\\theta$ that _minimizes_ this error:\n",
    "\n",
    "$$ \\theta_* = {\\arg\\min_\\theta} \\|X \\theta - y\\|_2^2. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the optimization problem\n",
    "\n",
    "Recall from calculus that you can minimize (or maximize) a continuous function $f(x)$ in a single variable $x$ by computing its derivative $\\left.\\frac{df}{dx}\\right|_{x=x_*}$, setting it to zero, and then solving for $x_*$.\n",
    "\n",
    "> **Example.** Let $f(x) \\equiv a x^2 + b x + c$. Then its maximum or minimum occurs at\n",
    ">\n",
    "> $$\n",
    "    \\left. \\frac{df}{dx} \\right|_{x=x_*} = 2 a x_* + b = 0,\n",
    "  $$\n",
    ">\n",
    "> or when\n",
    "> \n",
    "> $$\n",
    "    x_* = -\\frac{b}{2 a}.\n",
    "  $$\n",
    ">\n",
    "> To show whether this value is a maximum, a minimum, or a saddle-point, you would look at the second derivative. But let's skip that detail for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the setting of multivariable calculus, the procedure is the same. Let $g(\\theta)$ be the (scalar) function to minimize or maximize, where $\\theta$ is a vector. The moral equivalent of computing the first-derivative of a scalar function in a single variable is to compute the _gradient_ of the scalar function $g$ with respect to the vector variable $\\theta$,\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta g(\\theta) \\equiv\n",
    "  \\left(\\begin{array}{c}\n",
    "    \\frac{\\partial g}{\\partial \\theta_0} \\\\\n",
    "    \\frac{\\partial g}{\\partial \\theta_1} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\frac{\\partial g}{\\partial \\theta_{n-1}}\n",
    "  \\end{array}\\right),\n",
    "$$\n",
    "\n",
    "where $\\frac{\\partial g}{\\partial \\theta_i}$ is the partial derivative of $g$ with respect to $\\theta_i$. (To compute a partial derivative with respect to $\\theta_i$, take the ordinary derivative with respect to $\\theta_i$ while treating all other $\\theta_{j \\neq i}$ as constants.) The gradient produces a _vector_ of these partial derivatives.\n",
    "\n",
    "> **Example.** Let $\\theta \\equiv \\left(\\begin{array}{c} \\theta_0 \\\\ \\theta_1 \\end{array}\\right)$ and $g(\\theta) \\equiv \\|\\theta\\|_2^2$. That is,\n",
    ">\n",
    "> $$ g(\\theta) = \\|\\theta\\|_2^2 \\Longrightarrow g(\\theta_0, \\theta_1) = \\theta_0^2 + \\theta_1^2. $$\n",
    ">\n",
    "> Then,\n",
    ">\n",
    "> $$\n",
    "    \\nabla_\\theta\\, g(\\theta)\n",
    "      = \\left(\\begin{array}{c}\n",
    "          \\frac{\\partial g}{\\partial \\theta_0} \\\\\n",
    "          \\frac{\\partial g}{\\partial \\theta_1}\n",
    "        \\end{array}\\right)\n",
    "      = \\left(\\begin{array}{c}\n",
    "          \\frac{\\partial}{\\partial \\theta_0} (\\theta_0^2 + \\theta_1^2) \\\\\n",
    "          \\frac{\\partial}{\\partial \\theta_1} (\\theta_0^2 + \\theta_1^2)\n",
    "        \\end{array}\\right)\n",
    "      = \\left(\\begin{array}{c}\n",
    "          2 \\theta_0 \\\\\n",
    "          2 \\theta_1\n",
    "        \\end{array}\\right)\n",
    "      = 2 \\theta.\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From its definition, you should be able to verify the following identities related to the gradient. Below, take $v$ and $w$ to be vectors of length $n$ and $M$ to be an $n \\times n$ matrix.\n",
    "\n",
    "1. $\\nabla_v (v^T w) = w$.\n",
    "2. $\\nabla_v (v^T v) = 2v$. (That is, generalize the example above to an $n$-vector.)\n",
    "3. $\\nabla_v (v^T M v) = (M + M^T)v$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing the optimal parameters, $\\theta_*$.** Armed with the gradient, we are now ready to minimize $g(\\theta) \\equiv \\|X \\theta - y\\|_2^2$.\n",
    "\n",
    "$$\n",
    "  \\begin{eqnarray}\n",
    "  \\theta_* = \\arg\\min_\\theta \\|X \\theta - y\\|_2^2\n",
    "    & \\implies & \\left. \\nabla_\\theta\\, g(\\theta) \\right|_{\\theta_*} = 0,\n",
    "  \\end{eqnarray}\n",
    "$$\n",
    "\n",
    "that is,\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "  \\nabla_{\\theta_*} \\|X\\theta_* - y\\|_2^2\n",
    "    & = & \\nabla_{\\theta_*} \\left( \\theta_*^T X^T X \\theta_* - 2 \\theta_*^T X^T y + y^T y \\right) \\\\\n",
    "    & = & 2 (X^T X \\theta_* - X^T y) \\\\\n",
    "    & = & 0.\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "In other words, the $\\theta_*$ at the minimum is the solution of $X^T X \\theta_* = X^T y$. This system is known as the _normal equations_. If the data matrix $X$ has full rank, then this equation will have a solution.\n",
    "\n",
    "> Again, we've glossed over the fact that you need one more step to show that $\\theta_*$ minimizes the above equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 1: Direct solution of the normal equations\n",
    "\n",
    "The preceding calculation immediately suggests the following numerical algorithm to estimate $\\theta_*$. Given $X$ and $y$, carry out these three steps:\n",
    "\n",
    "1. Form $C \\equiv X^T X$.\n",
    "2. Form $b \\equiv X^T y$.\n",
    "3. Solve $C \\theta_* = b$ for $\\theta_*$.\n",
    "\n",
    "Is this a good algorithm? There are at least three dimensions along which we might answer this question.\n",
    "\n",
    "1. Is it accurate enough?\n",
    "2. Is it fast enough?\n",
    "3. Is it memory-efficient enough?\n",
    "\n",
    "Let's examine these questions by experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample data set: Hypertension\n",
    "\n",
    "For our experiments, let's use the following data set.\n",
    "\n",
    "A researcher has collected data on patients with hypertension (high blood pressure). She wishes to know to what extent blood pressure can be predicted from other physiological factors.\n",
    "\n",
    "> This example comes from: https://onlinecourses.science.psu.edu/stat501/node/346.\n",
    "\n",
    "Here is the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VARIABLES = ['BP', 'Age', 'Weight', 'BSA', 'Dur', 'Pulse', 'Stress']\n",
    "df = pd.read_table ('bloodpress.txt', usecols=VARIABLES)\n",
    "print (\"The full dataset consists of {} observations of {} variables.\".format (len (df), len (VARIABLES)))\n",
    "print (\"Here are the first few observations ...\")\n",
    "display (df.head ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables are as follows. (See: https://onlinecourses.science.psu.edu/stat501/node/329)\n",
    "\n",
    "- `BP`: Blood pressure, in millimeters of mercury (mm Hg)\n",
    "- `Age`: Age in years\n",
    "- `Weight`: Weight in kilograms\n",
    "- `BSA`: Body surface area in squared meters\n",
    "- `Dur`: Duration of hypertension in years\n",
    "- `Pulse`: Basal pulse in beats per minute\n",
    "- `Stress`: Stress index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that our analysis task is to predict blood pressure (`BP`) from weight and body surface area (`Weight` and `BSA`), based on the following observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RESPONSE = 'BP'\n",
    "PREDICTORS = ['Weight', 'BSA']\n",
    "sns.pairplot (df[[RESPONSE] + PREDICTORS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have some experience with statistics, you'll recognize immediately that a) there is good reason to suspect a relationship (top row), but that b) weight and body surface area are also highly correlated. But let's not worry about that ... for the moment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Algorithm 1: Take 1\n",
    "\n",
    "Let's start by extracting the response as a vector $y$ and the predictors as a data matrix $X$ (including a dummy column of ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df.as_matrix ([RESPONSE])\n",
    "m = len (y)\n",
    "\n",
    "X_initial = df.as_matrix (PREDICTORS)\n",
    "X = np.insert (X_initial, [0], [[1.]] * m, axis=1)\n",
    "\n",
    "print (\"X (first five rows):\\n\")\n",
    "print (X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (1 points). Form the matrix $C = X^T X$, storing the result in a variable `C` (a Numpy matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6940b2de1a98c833aaa7ae97724ceb38",
     "grade": false,
     "grade_id": "C",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print (\"Your computed C:\\n\")\n",
    "print (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a2c7434e100d06b77ef1fee9a0f522b8",
     "grade": true,
     "grade_id": "C__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert C.shape == (3, 3)\n",
    "\n",
    "C_soln = np.load ('C_soln.npy')\n",
    "assert (C - C_soln <= 1e-11).all ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** (1 point). Form the vector $b = X^T y$ and store the result in a variable `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fd0fff5c28e6634d6966967dfb3c4e61",
     "grade": false,
     "grade_id": "b",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print ('Your computed b:')\n",
    "print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "faba1cbb5efd02db73a176deddf857a9",
     "grade": true,
     "grade_id": "b__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert b.shape == (3, 1)\n",
    "\n",
    "b_soln = np.load ('b_soln.npy')\n",
    "assert (b - b_soln <= 1e-9).all ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** (1 point). Solve the resulting system, $C \\theta_* = b$ for $\\theta_*$. Store your result in a variable, `theta_neq` (for \"theta from the normal equations\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8541106fa2ef9c2bb2c59df999a48048",
     "grade": false,
     "grade_id": "theta_neq",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print (\"Your computed optimal parameters, theta_neq:\")\n",
    "print (theta_neq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (1 point). Compute the residual of this solution, $r = X \\theta_* - y$. Store the result in a variable, `r_neq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "46d63d9f1f40854013959c70fadded7a",
     "grade": false,
     "grade_id": "r_neq",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print (\"Response and your computed residual:\")\n",
    "df_compare = pd.concat ([pd.DataFrame (data=y, columns=['y']),\n",
    "                         pd.DataFrame (data=r_neq, columns=['r_neq'])],\n",
    "                        axis=1)\n",
    "display (df_compare)\n",
    "\n",
    "r_neq_nsq = np.linalg.norm (r_neq, 2)**2\n",
    "print (\"\\nThe squared residual norm:\", r_neq_nsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "564eff250bf23b6801312e2c17918ec1",
     "grade": true,
     "grade_id": "r_neq__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert r_neq_nsq <= 52.0\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources of error\n",
    "\n",
    "We said before that one question we should ask about our algorithm is whether it is \"accurate enough.\" But what does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** (3 points). For any modeling problem, there will be several sources of error. Describe at least three such sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "db6d10078ad6b596db900850c330d0b0",
     "grade": true,
     "grade_id": "error_sources",
     "locked": false,
     "points": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to begin to understand error in a numerical computation is to consider how sensitive the computed solution is to perturbations to the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (2 points). Implement a function that returns an $m \\times n$ matrix whose entries are uniformly randomly distributed in the interval, $[0, \\epsilon]$ for a given value of $\\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4d23eccfd030186b01d38e8d4621dff8",
     "grade": false,
     "grade_id": "rand_eps",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def random_mat (m, n, eps):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "print (random_mat (3, 2, 1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a4336d33f6129fb3292119d4fd392224",
     "grade": true,
     "grade_id": "rand_eps__test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "Z = random_mat (5, 3, 1e-2)\n",
    "assert Z.shape == (5, 3)\n",
    "assert (Z <= 1e-2).all ()\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** (1 point). Use your `random_mat()` function to create a \"small perturbation,\" $\\Delta X$, to the input data matrix, $X$. Store this perturbation in a variable, `Delta_X`. The entries of `Delta_X` should lie in the interval $[-\\epsilon, \\epsilon]$, where $\\epsilon$ is given in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4d8733bf0e8795ccec5f41080e786443",
     "grade": false,
     "grade_id": "delta_X",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "EPSILON = 0.1\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print (\"First few rows of Delta_X:\")\n",
    "print (Delta_X[:5], \"\\n  ...\")\n",
    "\n",
    "print (\"\\nFirst few rows of Delta_y:\")\n",
    "print (Delta_y[:5], \"\\n  ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "96e19a42fd296eb1c2741771d6c5cea9",
     "grade": true,
     "grade_id": "delta_X__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert Delta_X.shape == X.shape\n",
    "assert (Delta_X[:, 0] <= 1e-15).all ()\n",
    "assert (np.abs (Delta_X) <= EPSILON).all ()\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** (2 points). Create a matrix $X_\\epsilon = X + \\Delta X$ and a vector $y_\\epsilon = y + \\Delta y$. Store these results in two variables, `X_eps` and `y_eps`.\n",
    "\n",
    "From these, the code that follows will create $C_\\epsilon \\equiv X_\\epsilon^T X_\\epsilon$ and $b_\\epsilon = X_\\epsilon^T y_\\epsilon$, stored as `C_eps` and `b_eps`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2c85ca01df9c01267e84c246b3f8577e",
     "grade": false,
     "grade_id": "C_eps",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print (\"Your computed X_eps:\")\n",
    "print (X_eps)\n",
    "\n",
    "print (\"\\nYour computed y_eps:\")\n",
    "print (y_eps)\n",
    "\n",
    "C_eps = X_eps.T.dot (X_eps)\n",
    "print (\"\\nC_eps:\")\n",
    "print (C_eps)\n",
    "\n",
    "b_eps = X_eps.T.dot (y_eps)\n",
    "print (\"\\nb_eps:\")\n",
    "print (b_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b265f242449ac4515d24f924642c634b",
     "grade": true,
     "grade_id": "C_eps__test",
     "locked": true,
     "points": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_eps_max = np.abs (X) + EPSILON\n",
    "y_eps_max = np.abs (y) + EPSILON\n",
    "C_eps_max = X_eps_max.T.dot (X_eps_max)\n",
    "b_eps_max = X_eps_max.T.dot (y_eps_max)\n",
    "\n",
    "delta_C_max = np.max (np.abs (C_eps_max - C))\n",
    "delta_b_max = np.max (np.abs (b_eps_max - b))\n",
    "\n",
    "print (delta_C_max / np.max (np.abs (C)), delta_b_max / np.max (np.abs (b)))\n",
    "\n",
    "assert (np.abs (C_eps - C) <= delta_C_max).all ()\n",
    "assert (np.abs (b_eps - b) <= delta_b_max).all ()\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9** (2 points). Solve the system $C_\\epsilon \\theta_\\epsilon = b_\\epsilon$ for $\\theta_\\epsilon$. Store the result in a variable, `theta_eps`. Also compute the residual, $r_\\epsilon = X_\\epsilon \\theta_\\epsilon - y_\\epsilon$ and store it as `r_eps`.\n",
    "\n",
    "> How does the computed solution compare to that of the unperturbed system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "32440872d2033e4b29f6afe5f1f4e9ea",
     "grade": false,
     "grade_id": "theta_eps",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "r_eps_nsq = np.linalg.norm (r_eps, 2)**2\n",
    "print (\"The squared-norm of the residual:\", r_eps_nsq)\n",
    "\n",
    "print (\"\\nYour computed theta_eps, compared to theta_neq:\")\n",
    "display (pd.concat ([pd.DataFrame (data=theta_neq, columns=['theta_neq']),\n",
    "                     pd.DataFrame (data=theta_eps, columns=['theta_eps'])],\n",
    "                    axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "447b97eabcbc1d58f4ab322ceab7f4f3",
     "grade": true,
     "grade_id": "theta_eps__test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert r_eps_nsq <= (1.1 * r_neq_nsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
