{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "# Important note!\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR_ID = \"\" # Please enter your GT login, e.g., \"rvuduc3\" or \"gtg911x\"\n",
    "COLLABORATORS = [] # list of strings of your collaborators' IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b11295002cc2b9549d6a2b01721b6701",
     "grade": true,
     "grade_id": "who__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_CHECK_ID = re.compile (r'''[a-zA-Z]+\\d+|[gG][tT][gG]\\d+[a-zA-Z]''')\n",
    "assert RE_CHECK_ID.match (YOUR_ID) is not None\n",
    "\n",
    "collab_check = [RE_CHECK_ID.match (i) is not None for i in COLLABORATORS]\n",
    "assert all (collab_check)\n",
    "\n",
    "del collab_check\n",
    "del RE_CHECK_ID\n",
    "del re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter / IPython version check.** The following code cell verifies that you are using the correct version of Jupyter/IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing PCA\n",
    "\n",
    "For our course's final class, let's take the conceptual ideas of a principal components analysis (PCA) and $k$-means clustering, and put them into practice analyzing a dataset that should be personally meaningful to you!\n",
    "\n",
    "For this notebook, you will need the following dataset:\n",
    "\n",
    "* https://t-square.gatech.edu/access/content/group/gtc-3bd6-e221-5b9f-b047-31c7564358b7/peeps3.zip\n",
    "\n",
    "You'll also need a bunch of modules; might as well preload those now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "def to_base64 (png):\n",
    "    return \"data:image/png;base64,\" + base64.b64encode (png).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook ()\n",
    "print (\"Bokeh version:\", bokeh.__version__)\n",
    "#!conda upgrade bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.palettes import brewer\n",
    "\n",
    "def make_color_map (values):\n",
    "    \"\"\"Given a collection of discrete values, generate a color map.\"\"\"\n",
    "    unique_values = np.unique (values) # values must be discrete\n",
    "    num_unique_values = len (unique_values)\n",
    "    min_palette_size = min (brewer['Set1'].keys ())\n",
    "    max_palette_size = max (brewer['Set1'].keys ())\n",
    "    assert num_unique_values <= max_palette_size\n",
    "    palette = brewer['Set1'][max (min_palette_size, num_unique_values)]\n",
    "    color_map = dict (zip (unique_values, palette))\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://bokeh.pydata.org/en/latest/docs/user_guide/tools.html#userguide-tools-inspectors\n",
    "from bokeh.io import show\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import PanTool, BoxZoomTool, ResizeTool, HoverTool, CrosshairTool, ResetTool\n",
    "\n",
    "def make_scatter2d_images (x, y, names=None, image_files=None, clustering=None):\n",
    "    source_data = dict (x=x, y=y)\n",
    "    if names is not None:\n",
    "        source_data[\"desc\"] = names\n",
    "        tooltips_desc = \"\"\"<span style=\"font-size: 17px; font-weight: bold;\">@desc</span>\"\"\"\n",
    "    else:\n",
    "        tooltips_desc = \"\"\n",
    "        \n",
    "    if image_files is not None:\n",
    "        source_data[\"imgs\"] = image_files\n",
    "        tooltips_images = \"\"\"\n",
    "            <div>\n",
    "                <img\n",
    "                    src=\"@imgs\" height=\"42\" alt=\"@imgs\" width=\"42\"\n",
    "                    style=\"float: left; margin: 0px 15px 15px 0px;\"\n",
    "                    border=\"2\"\n",
    "                ></img>\n",
    "            </div>\n",
    "        \"\"\"\n",
    "    else:\n",
    "        tooltips_images = \"\"\n",
    "        \n",
    "    source = ColumnDataSource (data=source_data)\n",
    "    hover = HoverTool (tooltips=\"\"\"\n",
    "        <div>\n",
    "            {}\n",
    "            <div>\n",
    "                {}\n",
    "                <span style=\"font-size: 15px; color: #966;\">[$index]</span>\n",
    "            </div>\n",
    "            <div>\n",
    "                <span style=\"font-size: 15px;\">Location</span>\n",
    "                <span style=\"font-size: 10px; color: #696;\">($x, $y)</span>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\".format (tooltips_images, tooltips_desc))\n",
    "\n",
    "    TOOLS = [PanTool (), BoxZoomTool (), ResizeTool (), hover, CrosshairTool (), ResetTool ()]\n",
    "    p = figure (width=600, height=300, tools=TOOLS)\n",
    "    \n",
    "    if clustering is not None:\n",
    "        color_map = make_color_map (clustering)\n",
    "        cluster_colors = [color_map[c] for c in clustering]\n",
    "        p.circle (x='x', y='y',\n",
    "                  fill_color=cluster_colors,\n",
    "                  line_color=cluster_colors,\n",
    "                  size=5, source=source)\n",
    "    else:\n",
    "        p.circle (x='x', y='y', size=5, source=source)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans, vq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap: Solving the PCA problem\n",
    "\n",
    "Recall the basic algorithm to compute a PCA, the theory of which is explained in [this lab's accompanying notes](./pca-svd-notes.ipynb) and in the interactive visual demo of which appears at http://setosa.io/ev/principal-component-analysis/.\n",
    "\n",
    "You are given a set of $m-1$ data points or observations, $X \\equiv (\\hat{x}_0, \\hat{x}_1, \\cdots, \\hat{x}_{m-1})^T$. Each observation consists of $d$ measured predictors, which we represent by the $d$-dimensional vector $x_i \\in \\mathbb{R}^d$. You wish to find a $k$-dimensional representation of these points, where $k \\leq d$. To do so, you run the PCA procedure, which identifies a $k$-dimensional subspace in terms of $k$ orthogonal vectors (\"axes\"); these vectors are the _principal components_.\n",
    "\n",
    "1. If the data are not centered, transform them accordingly. In particular, ensure that their mean is 0, i.e., $\\displaystyle \\frac{1}{m} \\sum_{i=0}^{m-1} \\hat{x}_i = 0$.\n",
    "2. Compute the $k$-truncated SVD, $X \\approx U_k \\Sigma_k V_k^T$. The truncated SVD is just the subset of singular vectors corresponding to the largest $k$ singular values.\n",
    "3. Choose $v_0, v_1, \\ldots, v_{k-1}$ as the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "\n",
    "If you haven't done so already, download and unpack the dataset into this notebook's working directory.\n",
    "\n",
    "The data set is a bunch of goofy images. Let's look at one, selected at random. I swear I picked it randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goofy = Image.open ('peeps/scollins46--spencer.tiff', 'r') # Load an image\n",
    "goofy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert this image into a Numpy array, and then also to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def im2gnp (image):\n",
    "    \"\"\"Converts a PIL image into an image stored as a 2-D Numpy array in grayscale.\"\"\"\n",
    "    return np.array (image.convert ('L'))\n",
    "\n",
    "def gnp2im (image_np):\n",
    "    \"\"\"Converts an image stored as a 2-D grayscale Numpy array into a PIL image.\"\"\"\n",
    "    return Image.fromarray (image_np.astype (np.uint8), mode='L')\n",
    "\n",
    "def imshow_gray (im, ax=None):\n",
    "    if ax is None:\n",
    "        f = plt.figure ()\n",
    "        ax = plt.axes ()\n",
    "    ax.imshow (im,\n",
    "               interpolation='nearest',\n",
    "               cmap=plt.get_cmap ('gray'))                   \n",
    "    \n",
    "goofy_np_gray = np.array (goofy.convert ('L'))\n",
    "imshow_gray (goofy_np_gray)\n",
    "print (\"What a ham!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load all the images as grayscale into a list of Numpy arrays, `original_images`, along with an array `image_names` to hold a name for each image. (The names are extracted from the image filename.)\n",
    "\n",
    "> You may need to adjust the filepath below if this code does not work for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_images = []\n",
    "image_names = []\n",
    "for base, dirs, files in os.walk ('peeps'):\n",
    "    for filename in files:\n",
    "        name_tiff = re.match (r'^(.*)\\.tiff$', filename)\n",
    "        if name_tiff:\n",
    "            filepath = os.path.join (base, filename)\n",
    "            im = im2gnp (Image.open (filepath, 'r'))\n",
    "            key = name_tiff.groups (0)[0]\n",
    "            \n",
    "            original_images.append (im)\n",
    "            image_names.append (key)\n",
    "            \n",
    "print (\"Found\", len (original_images), \"goofy images.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will sometimes be helpful to have a friendly name for each image; the following code collects those names, extracting them from the `image_names[:]` list computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = []\n",
    "for key in image_names:\n",
    "    key_fields = re.match (r'^(.*)--(.*)$', key)\n",
    "    assert key_fields is not None\n",
    "    names.append (key_fields.groups ()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the latter part of this notebook creates an interactive visualization, for which we will need thumbnail versions of these images. The following code creates those thumbnails. It stores them as a list, `thumbnails[:]`, of Base64-encoded binary `PNG` data, which can be embedded directly into HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thumbnails = []\n",
    "for gnp in original_images:\n",
    "    im = gnp2im (gnp)\n",
    "    memout = BytesIO ()\n",
    "    im.save (memout, format='png')\n",
    "    thumbnails.append (to_base64 (memout.getvalue ()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the images\n",
    "\n",
    "To apply PCA, we'll want to preprocess the images in various ways.\n",
    "\n",
    "To begin with, observe that the images come in all shapes and sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_rows, min_cols = sys.maxsize, sys.maxsize\n",
    "max_rows, max_cols = 0, 0\n",
    "for (i, image) in enumerate (original_images):\n",
    "    r, c = image.shape[0], image.shape[1]\n",
    "    print ('%d:' % i, image_names[i], \"--\", r, \"x\", c, \"pixels\")\n",
    "    \n",
    "    min_rows = min (min_rows, r)\n",
    "    max_rows = max (max_rows, r)\n",
    "    min_cols = min (min_cols, c)\n",
    "    max_cols = max (max_cols, c)\n",
    "    \n",
    "print (\"\\n==> Least common image size:\", min_rows, \"x\", min_cols, \"pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (2 points). Suppose the least common image size is $r_0 \\times c_0$ pixels, and $s_0 = \\min (r_0, c_0)$ is the smallest dimension. Crop each $r \\times c$ image so that it is $s_0 \\times s_0$ in size. If $r > s_0$, then crop out any extra rows on the bottom of the image; and if $c > s_0$, then center the columns of the image. Store the output images in a 3-D Numpy array called `images[:, :, :]`, where `images[k, :, :]` is the `k`-th image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3b47e664170a636a10756a4474cdcf79",
     "grade": false,
     "grade_id": "recenter",
     "locked": false,
     "points": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def recenter (image, min_dim):\n",
    "    # min_dim == $s_0$ in the instructions\n",
    "    r, c = image.shape\n",
    "    \n",
    "    # Compute four variables, `top`, `left`, `bot`,\n",
    "    # and `right` so that the `return` statement\n",
    "    # returns the recentered image.\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return image[top:bot, left:right]\n",
    "\n",
    "# Quick test\n",
    "min_dim = min (min_rows, min_cols)\n",
    "image0 = original_images[0]\n",
    "\n",
    "print (\"Recentering: Before = {} x {} pixels; after = {} x {} pixels.\".format (image0.shape[0],\n",
    "                                                                               image0.shape[1],\n",
    "                                                                               min_dim,\n",
    "                                                                               min_dim))\n",
    "image0_recentered = recenter (image0, min_dim)\n",
    "\n",
    "fig, axs = plt.subplots (1, 2, figsize=(10, 5))\n",
    "imshow_gray (image0, ax=axs[0])\n",
    "imshow_gray (image0_recentered, ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0096a1a00e908407988289b8bd8ce9df",
     "grade": true,
     "grade_id": "recenter_test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Re-center images to a common size\n",
    "min_dim = min (min_rows, min_cols)\n",
    "images_recentered = np.zeros ((len (original_images), min_dim, min_dim))\n",
    "for (k, image) in enumerate (original_images):\n",
    "    images_recentered[k, :, :] = recenter (image, min_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** (2 points). Compute an \"average\" image, taken as the elementwise (pixelwise) mean over all images. Store the result in a `min_dim` $\\times$ `min_dim` Numpy array called, `mean_image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "076c4c9160b8134c5fd226588a3a288f",
     "grade": false,
     "grade_id": "mean_image",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Store your result in a variable called `mean_image`\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "    \n",
    "# How would you describe this \"average\" person?\n",
    "imshow_gray (mean_image)\n",
    "gnp2im (mean_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** (2 points). Recall that PCA requires centered points. Let's do that by subtracting the mean image from every image. Use the recentered images computed in one of the above tests (`images_recentered`) and store the result in a new array, `images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "db85d722b0028198c4ba492bf5ebde10",
     "grade": false,
     "grade_id": "sub_mean",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axs = plt.subplots (1, 4, figsize=(10, 40))\n",
    "imshow_gray (images[0, :, :] + mean_image, ax=axs[0])\n",
    "imshow_gray (images[0, :, :], ax=axs[1]) # Compare this to the original.\n",
    "imshow_gray (images[-1, :, :] + mean_image, ax=axs[2])\n",
    "imshow_gray (images[-1, :, :], ax=axs[3]) # Compare this to the original.\n",
    "print (\"why if it isn't the lovely/handsome pair, {} and {}!\".format (names[0], names[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8c7be8922f89427cb3f6bc22715c4241",
     "grade": true,
     "grade_id": "sub_mean_test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "max_abs_sum = np.max (np.abs ((np.sum (images, axis=0))))\n",
    "max_abs_sum_bound = np.finfo (float).eps * (len (images) ** 2) * np.max (images)\n",
    "print (max_abs_sum, \"<=\", max_abs_sum_bound, \"?\")\n",
    "assert max_abs_sum <= max_abs_sum_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From image set to a data matrix and back again\n",
    "\n",
    "For PCA, you need a data matrix. Here is some code to convert our 3-D array of images into a 2-D data matrix, where we \"flatten\" each image into a 1-D vector by a simple `reshape` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create m x d data matrix\n",
    "m = len (images)\n",
    "d = min_dim * min_dim\n",
    "X = np.reshape (images, (m, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To get back to an image, just reshape it again\n",
    "imshow_gray (np.reshape (X[int (len (X)/2), :], (min_dim, min_dim)))\n",
    "print (names[int (len (X)/2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (2 points). Compute the SVD of `X`. Store the result in three arrays, `U`, `Sigma`, and `VT`, where `U` holds $U$, `Sigma` holds just the diagonal entries of $\\Sigma$, and `VT` holds $V^T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "85f30e97890e7c5271ef1cfd8931a34b",
     "grade": false,
     "grade_id": "svd",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a70472e09360884771cea97f3b62952b",
     "grade": true,
     "grade_id": "svd_test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check on dimensions\n",
    "print (\"X:\", X.shape)\n",
    "print (\"U:\", U.shape)\n",
    "print (\"Sigma:\", Sigma.shape)\n",
    "print (\"V^T:\", VT.shape)\n",
    "\n",
    "assert X.shape == (len (images), min_dim * min_dim)\n",
    "assert U.shape == (len (images), len (images))\n",
    "assert Sigma.shape == (len (images),)\n",
    "assert VT.shape == (len (images), min_dim * min_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code looks at Sigma. The collection of $\\sigma_i$ values is also referred to as the _spectrum_ of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def peek_Sigma (Sigma, ret_df=False):\n",
    "    k = len (Sigma)\n",
    "    df_Sigma = pd.DataFrame ()\n",
    "    df_Sigma['i'] = np.arange (k)\n",
    "    df_Sigma['sigma_i'] = Sigma\n",
    "    Sigma_sq = np.power (Sigma, 2)\n",
    "    Err_sq = np.sum (Sigma_sq) - np.cumsum (Sigma_sq)\n",
    "    Err_sq[Err_sq < 0] = 0\n",
    "    Err = np.sqrt (Err_sq)\n",
    "    Relerr = Err / (Sigma[0] + Err[0])\n",
    "    df_Sigma['sigma_i^2'] = Sigma_sq\n",
    "    df_Sigma['err_i^2'] = Err_sq\n",
    "    df_Sigma['err_i'] = Err\n",
    "    df_Sigma['relerr_i'] = Relerr\n",
    "    print (\"Singular values:\")\n",
    "    display (df_Sigma.head ())\n",
    "    print (\"  ...\")\n",
    "    display (df_Sigma.tail ())\n",
    "    \n",
    "    f, ax = plt.subplots (figsize=(7, 7))\n",
    "    #ax.set (yscale=\"log\")\n",
    "    sns.regplot (\"i\", \"sigma_i\", df_Sigma, ax=ax, fit_reg=False)\n",
    "    if ret_df:\n",
    "        return df_Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_Sigma = peek_Sigma (Sigma, ret_df=True)\n",
    "\n",
    "# Adds a red line to the plot: y ~ sigma_0 / sqrt(i+1)\n",
    "plt.plot (df_Sigma['i'], df_Sigma['sigma_i'][0]*np.power (df_Sigma['i']+1, -0.5),\n",
    "          color=\"red\", linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** (2 points). Does the spectrum of these data decay quickly or slowly? How should that affect your choice of $k$, if you are considering a $k$-truncated SVD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2ff441cfc9f56b414f8edaa9c39aa032",
     "grade": true,
     "grade_id": "spectrum_decay",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (2 points). Plot the first few principal components as images. What do they appear to capture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2a0f58e0d29828ff30803c53f7d0f707",
     "grade": true,
     "grade_id": "inspect_pcs",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** (2 points). Write some code to compute a new matrix `Y`, which is the original data matrix projected onto the first `num_components` principal components.\n",
    "\n",
    "> You can use the code cell below, which calls `make_scatter2d_images`, to create an interactive plot of your projection. Does it reveal any interesting groupings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "37d4b9b82ae6398554e99549d613ad49",
     "grade": true,
     "grade_id": "Y",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "num_components = 2 # Number of principal components\n",
    "\n",
    "# Define `Y`:\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "assert Y.shape == (len (X), num_components)\n",
    "\n",
    "p = make_scatter2d_images (Y[:, 0], Y[:, 1],\n",
    "                           names=names,\n",
    "                           image_files=thumbnails)\n",
    "show (p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** (2 points). Run $k$-means on the projected data, `Y[:m, :num_components]`, to try to identify up to `num_clusters` clusters. Store the cluster centers in an array `centers[:num_clusters, :2]` and the cluster labels in an array `clustering[:m]`.\n",
    "\n",
    "> You may use Scipy's `kmeans()` routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6ab976f3e9768ab3f8ddf945499409fd",
     "grade": true,
     "grade_id": "run_kmeans",
     "locked": false,
     "points": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "num_clusters = 4\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print (centers)\n",
    "\n",
    "p = make_scatter2d_images (Y[:, 0], Y[:, 1],\n",
    "                           names=names,\n",
    "                           image_files=thumbnails,\n",
    "                           clustering=clustering)\n",
    "show (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_kcurve = pd.DataFrame (columns=['k', 'distortion']) \n",
    "for i in range(1,10):\n",
    "    _, distortion = kmeans (Y, i)\n",
    "    df_kcurve.loc[i] = [i, distortion]\n",
    "df_kcurve.plot(x=\"k\", y=\"distortion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Today's notebook uses a bunch of library modules and coding tricks; if you want to learn more, see these references.\n",
    "\n",
    "_Image manipulation_\n",
    "* Working with TIFFs: http://stackoverflow.com/questions/7569553/working-with-tiffs-import-export-in-python-using-numpy\n",
    "* Displaying PIL images inline: http://stackoverflow.com/questions/26649716/how-to-show-pil-image-in-ipython-notebook\n",
    "* Convert to grayscale: http://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python\n",
    "\n",
    "_PCA in Python_\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
