{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "# Important note!\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR_ID = \"\" # Please enter your GT login, e.g., \"rvuduc3\" or \"gtg911x\"\n",
    "COLLABORATORS = [] # list of strings of your collaborators' IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b11295002cc2b9549d6a2b01721b6701",
     "grade": true,
     "grade_id": "who__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_CHECK_ID = re.compile (r'''[a-zA-Z]+\\d+|[gG][tT][gG]\\d+[a-zA-Z]''')\n",
    "assert RE_CHECK_ID.match (YOUR_ID) is not None\n",
    "\n",
    "collab_check = [RE_CHECK_ID.match (i) is not None for i in COLLABORATORS]\n",
    "assert all (collab_check)\n",
    "\n",
    "del collab_check\n",
    "del RE_CHECK_ID\n",
    "del re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter / IPython version check.** The following code cell verifies that you are using the correct version of Jupyter/IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: NYC 311 calls [22 points]\n",
    "\n",
    "This notebook derives from a [demo by the makers of plot.ly](https://plot.ly/ipython-notebooks/big-data-analytics-with-pandas-and-sqlite/). We've adapted it to use [Bokeh](http://bokeh.pydata.org/en/latest/).\n",
    "\n",
    "You will start with a large database of complaints filed by residents of New York City since 2010 via 311 calls. The full dataset is available at the [NYC open data portal](https://nycopendata.socrata.com/data). At about 6 GB and 10 million complaints, you can infer that a) you might not want to read it all into memory at once, and b) NYC residents are really whiny. (Maybe only conclusion \"a\" is valid.) The notebook then combines the use of `sqlite`, `pandas`, and `bokeh`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, as a quick test let's make a simple plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following module defines a couple functions from Lab 4 that we'll need again in this lab, in particular, `tibbles_are_equivalent()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cse6040utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a Pandas data frame\n",
    "names = ['Bob','Jessica','Mary','John','Mel']\n",
    "births = [968, 155, 77, 578, 973]\n",
    "name_birth_pairs = list (zip (names, births))\n",
    "baby_names = pd.DataFrame(data=name_birth_pairs, columns=['Names', 'Births'])\n",
    "display (baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Bar\n",
    "from bokeh.io import show, output_notebook\n",
    "output_notebook ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show (Bar (baby_names, values='Births', label='Names', color='Names', width=300, height=300, legend=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download a sample dataset.** Next, grab a copy of today's dataset, which is a small (~ 20%) subset of the full dataset:\n",
    "\n",
    "* [SQLite DB, ~ 257 MiB] http://cse6040.gatech.edu/datasets/NYC-311-2M.db\n",
    "\n",
    "Let's connect to this database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQLite database filename\n",
    "DB_FILENAME = 'NYC-311-2M.db'\n",
    "\n",
    "# Connect\n",
    "import sqlite3 as db\n",
    "disk_engine = db.connect (DB_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preview the data.** This sample database has just a single table, named `data`. Let's query it and see how long it takes to read. To carry out the query, we will use the SQL reader built into `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"Reading ...\")\n",
    "start_time = time.time ()\n",
    "\n",
    "# Perform SQL query through the disk_engine connection.\n",
    "# The return value is a pandas data frame.\n",
    "df = pd.read_sql_query ('select * from data', disk_engine)\n",
    "\n",
    "elapsed_time = time.time () - start_time\n",
    "print (\"==> Took %g seconds.\" % elapsed_time)\n",
    "\n",
    "# Dump the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More SQL stuff\n",
    "\n",
    "**Partial queries: `LIMIT` clause.** The preceding command was overkill for what we wanted, which was just to preview the table. Instead, we could have used the `LIMIT` option to ask for just a few results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select *\n",
    "    from data\n",
    "    limit 5\n",
    "'''\n",
    "start_time = time.time ()\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "elapsed_time = time.time () - start_time\n",
    "print (\"==> LIMIT version took %g seconds.\" % elapsed_time)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the `LIMIT` feature to create a generic function that \"peeks\" at the first few entries of any table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def peek_table (db, name, num=5):\n",
    "    \"\"\"\n",
    "    Given a database connection (`db`), prints both the number of\n",
    "    records in the table as well as its first few entries.\n",
    "    \"\"\"\n",
    "    count = '''select count (*) FROM {table}'''.format (table=name)\n",
    "    peek = '''select * from {table} limit {limit}'''.format (table=name, limit=num)\n",
    "    \n",
    "    print (\"Total number of records:\")\n",
    "    display (pd.read_sql_query (count, db))\n",
    "    \n",
    "    print (\"First {} entries:\".format (num))\n",
    "    display (pd.read_sql_query (peek, db))\n",
    "    \n",
    "peek_table (disk_engine, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set membership: `IN` operator.** Another common idiom is to ask for rows whose attributes fall within a set, for which you can use the `IN` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select ComplaintType, Descriptor, Agency\n",
    "    from data\n",
    "    where Agency in (\"NYPD\", \"DOB\")\n",
    "    limit 10\n",
    "'''\n",
    "\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding unique values: `DISTINCT` qualifier.** Yet another common idiom is to ask for the unique values of some attribute, for which you can use the `DISTINCT` qualifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = 'select distinct City FROM data'\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "\n",
    "print (\"Found %d unique cities. The first few are:\" % len (df))\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming columns: `AS` operator.** Sometimes you might want to rename a result column. For instance, the following query counts the number of complaints by \"Agency,\" using the `COUNT(*)` function and `GROUP BY` clause, which we discussed in an earlier lab. If you wish to refer to the counts column of the resulting data frame, you can give it a more \"friendly\" name using the `AS` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select Agency, count(*) as NumComplaints\n",
    "    from data\n",
    "    group by Agency\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ordering results: `ORDER` clause.** You can also order the results. For instance, suppose we want to execute the previous query by number of complaints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select Agency, count(*) as NumComplaints\n",
    "    from data\n",
    "    group by Agency\n",
    "    order by NumComplaints\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.tail ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the above example prints the bottom (tail) of the data frame. You could have also asked for the query results in reverse (descending) order, by prefixing the `ORDER BY` attribute with a `-` (minus) symbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select Agency, count(*) as NumComplaints\n",
    "    from data\n",
    "    group by Agency\n",
    "    order by -NumComplaints\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df.head ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we can plot all of this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Disable auto-sorting x-axis:\n",
    "#   https://github.com/bokeh/bokeh/issues/2924\n",
    "# + http://bokeh.pydata.org/en/latest/docs/gallery/stacked_bar_chart.html\n",
    "from bokeh.charts.attributes import cat\n",
    "\n",
    "show (Bar (df[:20],\n",
    "           title='Top 20 agencies by number of complaints',\n",
    "           values='NumComplaints',\n",
    "           label=cat (columns=['Agency'], sort=False),\n",
    "           width=800, height=400, legend=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (2 points). Create a string, `query`, that contains an SQL query that returns the number of complaints by type. The columns should be named `type` and `freq`, and the results should be sorted in descending order by `freq`.\n",
    "\n",
    "> What is the most common type of complaint? What, if anything, does it tell you about NYC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "02c545e88c5dbdd207e79390140a6648",
     "grade": false,
     "grade_id": "complaints",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a string, `query`, containing your query:\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Runs your `query`:\n",
    "df_complaint_freq = pd.read_sql_query (query, disk_engine)\n",
    "df_complaint_freq.head ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ba2225530b41553e9533a726e87b0546",
     "grade": true,
     "grade_id": "complaints_test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"Top 10 complaints:\")\n",
    "display (df_complaint_freq.head (10))\n",
    "\n",
    "soln = ['HEAT/HOT WATER', 'Street Condition', 'Street Light Condition', 'Blocked Driveway', 'Illegal Parking', 'UNSANITARY CONDITION', 'PAINT/PLASTER', 'Water System', 'PLUMBING', 'Noise', 'Noise - Street/Sidewalk', 'Traffic Signal Condition', 'Noise - Commercial', 'DOOR/WINDOW', 'WATER LEAK', 'Dirty Conditions', 'Sewer', 'Sanitation Condition', 'DOF Literature Request', 'ELECTRIC', 'Rodent', 'FLOORING/STAIRS', 'General Construction/Plumbing', 'Building/Use', 'Broken Muni Meter', 'GENERAL', 'Missed Collection (All Materials)', 'Benefit Card Replacement', 'Derelict Vehicle', 'Noise - Vehicle', 'Damaged Tree', 'Consumer Complaint', 'Derelict Vehicles', 'Taxi Complaint', 'Overgrown Tree/Branches', 'Graffiti', 'Snow', 'Opinion for the Mayor', 'APPLIANCE', 'Maintenance or Facility', 'Animal Abuse', 'Dead Tree', 'HPD Literature Request', 'Root/Sewer/Sidewalk Condition', 'SAFETY', 'Elevator', 'Food Establishment', 'SCRIE', 'Air Quality', 'Agency Issues', 'Construction', 'Highway Condition', 'Other Enforcement', 'Water Conservation', 'Sidewalk Condition', 'Indoor Air Quality', 'Street Sign - Damaged', 'Traffic', 'Plumbing', 'Fire Safety Director - F58', 'Homeless Person Assistance', 'Homeless Encampment', 'Special Enforcement', 'Street Sign - Missing', 'Noise - Park', 'Vending', 'For Hire Vehicle Complaint', 'Food Poisoning', 'Special Projects Inspection Team (SPIT)', 'Hazardous Materials', 'Electrical', 'DOT Literature Request', 'Litter Basket / Request', 'Taxi Report', 'Illegal Tree Damage', 'DOF Property - Reduction Issue', 'Unsanitary Animal Pvt Property', 'Asbestos', 'Lead', 'Vacant Lot', 'DCA / DOH New License Application Request', 'Street Sign - Dangling', 'Smoking', 'Violation of Park Rules', 'OUTSIDE BUILDING', 'Animal in a Park', 'Noise - Helicopter', 'School Maintenance', 'DPR Internal', 'Boilers', 'Industrial Waste', 'Sweeping/Missed', 'Overflowing Litter Baskets', 'Non-Residential Heat', 'Curb Condition', 'Drinking', 'Standing Water', 'Indoor Sewage', 'Water Quality', 'EAP Inspection - F59', 'Derelict Bicycle', 'Noise - House of Worship', 'DCA Literature Request', 'Recycling Enforcement', 'ELEVATOR', 'DOF Parking - Tax Exemption', 'Broken Parking Meter', 'Request for Information', 'Taxi Compliment', 'Unleashed Dog', 'Urinating in Public', 'Unsanitary Pigeon Condition', 'Investigations and Discipline (IAD)', 'Bridge Condition', 'Ferry Inquiry', 'Bike/Roller/Skate Chronic', 'Public Payphone Complaint', 'Vector', 'BEST/Site Safety', 'Sweeping/Inadequate', 'Disorderly Youth', 'Found Property', 'Mold', 'Senior Center Complaint', 'Fire Alarm - Reinspection', 'For Hire Vehicle Report', 'City Vehicle Placard Complaint', 'Cranes and Derricks', 'Ferry Complaint', 'Illegal Animal Kept as Pet', 'Posting Advertisement', 'Harboring Bees/Wasps', 'Panhandling', 'Scaffold Safety', 'OEM Literature Request', 'Plant', 'Bus Stop Shelter Placement', 'Collection Truck Noise', 'Beach/Pool/Sauna Complaint', 'Complaint', 'Compliment', 'Illegal Fireworks', 'Fire Alarm - Modification', 'DEP Literature Request', 'Drinking Water', 'Fire Alarm - New System', 'Poison Ivy', 'Bike Rack Condition', 'Emergency Response Team (ERT)', 'Municipal Parking Facility', 'Tattooing', 'Unsanitary Animal Facility', 'Animal Facility - No Permit', 'Miscellaneous Categories', 'Misc. Comments', 'Literature Request', 'Special Natural Area District (SNAD)', 'Highway Sign - Damaged', 'Public Toilet', 'Adopt-A-Basket', 'Ferry Permit', 'Invitation', 'Window Guard', 'Parking Card', 'Illegal Animal Sold', 'Stalled Sites', 'Open Flame Permit', 'Overflowing Recycling Baskets', 'Highway Sign - Missing', 'Public Assembly', 'DPR Literature Request', 'Fire Alarm - Addition', 'Lifeguard', 'Transportation Provider Complaint', 'DFTA Literature Request', 'Bottled Water', 'Highway Sign - Dangling', 'DHS Income Savings Requirement', 'Legal Services Provider Complaint', 'Foam Ban Enforcement', 'Tunnel Condition', 'Calorie Labeling', 'Fire Alarm - Replacement', 'X-Ray Machine/Equipment', 'Sprinkler - Mechanical', 'Hazmat Storage/Use', 'Tanning', 'Radioactive Material', 'Rangehood', 'SRDE', 'Squeegee', 'Building Condition', 'SG-98', 'Standpipe - Mechanical', 'AGENCY', 'Forensic Engineering', 'Public Assembly - Temporary', 'VACANT APARTMENT', 'Laboratory', 'SG-99']\n",
    "assert all (soln == df_complaint_freq['type'])\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also visualize the result, as a bar chart showing complaint types on the x-axis and the number of complaints on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show (Bar (df_complaint_freq[:25],\n",
    "           title='Top 25 complaints',\n",
    "           values='freq',\n",
    "           label=cat (columns=['type'], sort=False),\n",
    "           width=800, height=400, legend=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple substring matching: the `LIKE` operator.** Suppose we just want to look at the counts for all complaints that have the word `noise` in them. You can use the `LIKE` operator combined with the string wildcard, `%`, to look for case-insensitive substring matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select ComplaintType as type, count(*) as freq\n",
    "    from data\n",
    "    where ComplaintType like '%noise%'\n",
    "    group by type\n",
    "    order by -freq\n",
    "'''\n",
    "\n",
    "df_noisy = pd.read_sql_query (query, disk_engine)\n",
    "df_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** (2 points). Create a string variable, `query`, that contains an SQL query that will return the top 10 most \"whiny\" cities in descending order of number of complaints. It should return two columns, one named `name` holding the name of the city, and one named `freq` holding the number of complaints by that city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1360beba933bca514fb725bb499e512a",
     "grade": false,
     "grade_id": "whiny_cities",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a string, `query`, containing your query:\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Runs your `query`:\n",
    "df_whiny_cities = pd.read_sql_query (query, disk_engine)\n",
    "df_whiny_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "134dd8ec7fdcb89fca3685b9a4cc7722",
     "grade": true,
     "grade_id": "whiny_cities__test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_whiny_cities['name'][0] == 'BROOKLYN'\n",
    "assert df_whiny_cities['name'][1] == 'NEW YORK'\n",
    "assert df_whiny_cities['name'][2] == 'BRONX'\n",
    "assert df_whiny_cities['name'][3] is None\n",
    "assert df_whiny_cities['name'][4] == 'STATEN ISLAND'\n",
    "\n",
    "print (\"\\n(Passed partial test.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You should notice two bits of funny behavior, namely, that cities are treated in a _case-sensitive_ manner and that `None` appears as a city. (Presumably this setting occurs when a complaint is non-localized or the city is not otherwise specified.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case-insensitive grouping: `COLLATE NOCASE`.** One way to carry out the preceding query in a case-insensitive way is to add a `COLLATE NOCASE` qualifier to the `GROUP BY` clause.\n",
    "\n",
    "Let's filter out the 'None' cases as well, while we are at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  SELECT City as name, COUNT(*) AS freq\n",
    "    FROM data\n",
    "    WHERE name <> 'None'\n",
    "    GROUP BY name COLLATE NOCASE\n",
    "    ORDER BY -freq\n",
    "    LIMIT 10\n",
    "'''\n",
    "df_whiny_cities2 = pd.read_sql_query (query, disk_engine)\n",
    "df_whiny_cities2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brooklyn is NYC's whiniest city. I knew it!\n",
    "\n",
    "Lastly, for later use, let's save the names of just the top 7 cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOP_CITIES = list (df_whiny_cities2.head (7)['name'])\n",
    "TOP_CITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** (1 point). Implement a function that takes a list of strings, `str_list`, and returns a single string consisting of each value, `str_list[i]`, enclosed by double-quotes and separated by a comma-space delimiters. For example, if\n",
    "\n",
    "```python\n",
    "   assert str_list == ['a', 'b', 'c', 'd']\n",
    "```\n",
    "\n",
    "then\n",
    "\n",
    "```python\n",
    "   assert strs_to_args (str_list) == '\"a\", \"b\", \"c\", \"d\"'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7442fc9df222086ca28971e94bfd9f74",
     "grade": false,
     "grade_id": "strs_to_args",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def strs_to_args (str_list):\n",
    "    \"\"\"Converts a list of strings to a comma-separated string argument list.\"\"\"\n",
    "    assert type (str_list) is list\n",
    "    assert all ([type (s) is str for s in str_list])\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "97d71d1cd959303e8da89843e4a57623",
     "grade": true,
     "grade_id": "strs_to_args__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"Your solution, applied to TOP_CITIES:\", strs_to_args (TOP_CITIES))\n",
    "\n",
    "TOP_CITIES_as_args = strs_to_args (TOP_CITIES)\n",
    "assert TOP_CITIES_as_args.lower () == \\\n",
    "       '\"BROOKLYN\", \"NEW YORK\", \"BRONX\", \"STATEN ISLAND\", \"Jamaica\", \"Flushing\", \"ASTORIA\"'.lower ()\n",
    "    \n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (3 points). Suppose we want to look at the number of complaints by type _and_ by city. Execute an SQL query to produce a tibble named `df_complaints_by_city` with the variables {`complaint_type`, `city_name`, `complaint_count`}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "678fce2c1c227a8e94d34045f548da32",
     "grade": false,
     "grade_id": "df_complaints_by_city",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a variable, `query`, containing your SQL query.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Previews the results of your query:\n",
    "display (df_complaints_by_city.head (10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2c60ed9d8fd234544a16c52da1931414",
     "grade": true,
     "grade_id": "df_complaints_by_city__test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"Reading instructor's solution...\")\n",
    "df_complaints_by_city_soln = pd.read_csv ('df_complaints_by_city_soln.csv')\n",
    "\n",
    "print (\"Checking...\")\n",
    "assert tibbles_are_equivalent (df_complaints_by_city,\n",
    "                               df_complaints_by_city_soln)\n",
    "\n",
    "print (\"\\n(Passed.)\")\n",
    "del df_complaints_by_city_soln"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use Bokeh to visualize the results as a stacked bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's consider only the top 25 complaints (by total)\n",
    "top_complaints = df_complaint_freq[:25]\n",
    "display (top_complaints)\n",
    "\n",
    "# Plot subset of data corresponding to the top complaints\n",
    "df_plot = top_complaints.merge (df_complaints_by_city,\n",
    "                                left_on=['type'],\n",
    "                                right_on=['complaint_type'],\n",
    "                                how='left')\n",
    "display (df_plot.head ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# See also:\n",
    "#   - http://bokeh.pydata.org/en/latest/docs/gallery/stacked_bar_chart.html\n",
    "#   - http://stackoverflow.com/questions/33022985/data-tooltips-in-bokeh-dont-show-data-showing-instead\n",
    "\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "p = Bar (df_plot,\n",
    "         values='complaint_count',\n",
    "         label=cat (columns=['type'], sort=False),\n",
    "         stack='city_name',\n",
    "         color='city_name',\n",
    "         width=800, height=400, legend='right_center',\n",
    "         tools=\"hover,crosshair,pan,box_zoom,wheel_zoom,save,resize,reset,help\")\n",
    "\n",
    "hover_tool = p.select( dict (type=HoverTool))\n",
    "hover_tool.tooltips = [('City', '@city_name'), ('Complaint', '@x'), (\"#\", \"@height{int}\")]\n",
    "\n",
    "show (p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** (3 points). Make a variation of the above stacked bar chart that shows, for each complaint type (x-axis), the _percentage_ of complaints attributed to each city.\n",
    "\n",
    "> Note: The normalized bars will not necessarily add up to 1. Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "f31f52055dbb5923365c3082b1a64e26",
     "grade": true,
     "grade_id": "norm_above",
     "locked": false,
     "points": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates and times in SQL\n",
    "\n",
    "Recall that the input data had a column with timestamps corresponding to when someone submitted a complaint. Let's quickly summarize some of the features in SQL and Python for reasoning about these timestamps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CreatedDate` column is actually a specially formatted date and time stamp, where you can query against by comparing to strings of the form, `YYYY-MM-DD hh:mm:ss`.\n",
    "\n",
    "For example, let's look for all complaints on September 15, 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select ComplaintType, CreatedDate, City\n",
    "    from data\n",
    "    where CreatedDate >= \"2015-09-15 00:00:00.0\"\n",
    "      and CreatedDate < \"2015-09-16 00:00:00.0\"\n",
    "    order by CreatedDate\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next example shows how to extract just the hour from the time stamp, using SQL's `strftime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select CreatedDate, strftime ('%H', CreatedDate) as Hour, ComplaintType\n",
    "    from data\n",
    "    limit 5\n",
    "'''\n",
    "df = pd.read_sql_query (query, disk_engine)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (3 points). Construct a tibble called `df_complaints_by_hour`, which contains the total number of complaints during a given hour of the day. That is, the variables should be {`hour`, `count`} where each observation is the total number of complaints (`count`) that occurred during a given `hour`.\n",
    "\n",
    "> Interpret `hour` as follows: when `hour` is `02`, that corresponds to the open time interval [`02:00:00`, `03:00:00.0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0973d1f3d797d1b39d338d2c73905626",
     "grade": false,
     "grade_id": "df_complaints_by_hour",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "display (df_complaints_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "393bdbc3a48e5291e1339710c16ed86a",
     "grade": true,
     "grade_id": "df_complaints_by_hour_test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"Reading instructor's solution...\")\n",
    "df_complaints_by_hour_soln = pd.read_csv ('df_complaints_by_hour_soln.csv')\n",
    "display (df_complaints_by_hour_soln)\n",
    "\n",
    "df_complaints_by_hour_norm = df_complaints_by_hour.copy ()\n",
    "df_complaints_by_hour_norm['hour'] = \\\n",
    "    df_complaints_by_hour_norm['hour'].apply (int)\n",
    "assert tibbles_are_equivalent (df_complaints_by_hour_norm,\n",
    "                               df_complaints_by_hour_soln)\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Bar (df_complaints_by_hour,\n",
    "         values='count',\n",
    "         label='hour',\n",
    "         legend=None)\n",
    "show (p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An unusual aspect of these data are the excessively large number of reports associated with hour 0 (midnight up to but excluding 1 am). The reason is that there are some complaints that are dated but with no associated time, which then by default becomes `00:00:00.000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select count (*)\n",
    "    from data\n",
    "    where strftime ('%H:%M:%f', CreatedDate) = '00:00:00.000'\n",
    "'''\n",
    "pd.read_sql_query (query, disk_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** (3 points). What is the most common hour for noise complaints? Compute a tibble called `df_noisy_by_hour` whose variables are {`hour`, `count`} and whose observations are the number of noise complaints that occurred during a given `hour`. Consider a \"noise complaint\" to be any complaint string containing the word `noise`. Be sure to filter out any dates _without_ an associated time, i.e., a timestamp of `00:00:00.000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2519d05a9f7b18466b152d20b0be88c9",
     "grade": false,
     "grade_id": "df_noisy_by_hour",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "display (df_noisy_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bb7bf35e08281fcf0d874bbcf5f1d4fa",
     "grade": true,
     "grade_id": "df_noisy_by_hour_test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"Reading instructor's solution...\")\n",
    "df_noisy_by_hour_soln = pd.read_csv ('df_noisy_by_hour_soln.csv')\n",
    "display (df_noisy_by_hour_soln)\n",
    "\n",
    "df_noisy_by_hour_norm = df_noisy_by_hour.copy ()\n",
    "df_noisy_by_hour_norm['hour'] = \\\n",
    "    df_noisy_by_hour_norm['hour'].apply (int)\n",
    "assert tibbles_are_equivalent (df_noisy_by_hour_norm,\n",
    "                               df_noisy_by_hour_soln)\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Bar (df_noisy_by_hour,\n",
    "         values='count',\n",
    "         label='hour',\n",
    "         legend=None)\n",
    "show (p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** (5 points). Create a line chart (see [Line](http://bokeh.pydata.org/en/latest/docs/reference/charts.html#line)) to show the fraction of complaints (y-axis) associated with each hour of the day (x-axis), with each complaint type shown as a differently colored line. Show just the top 5 complaints (`top_complaints[:5]`). Remember to exclude complaints with a zero-timestamp (i.e., `00:00:00.000`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "280124f2ac984097c40d682f7a7af997",
     "grade": true,
     "grade_id": "complaint_types_by_hour",
     "locked": false,
     "points": 5,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.charts import Line\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more\n",
    "\n",
    "- Find more open data sets on [Data.gov](https://data.gov) and [NYC Open Data](https://nycopendata.socrata.com)\n",
    "- Learn how to setup [MySql with Pandas and Plotly](http://moderndata.plot.ly/graph-data-from-mysql-database-in-python/)\n",
    "- Big data workflows with [HDF5 and Pandas](http://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
