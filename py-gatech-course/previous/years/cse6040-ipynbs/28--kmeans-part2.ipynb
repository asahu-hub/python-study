{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 6040, Fall 2015 [28]: K-means Clustering, Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time, we implemented the basic version of K-means. In this lecture we will explore some advanced techniques\n",
    "to improve the performance of K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv ('http://vuduc.org/cse6040/logreg_points_train.csv')\n",
    "points = df.as_matrix (['x_1', 'x_2'])\n",
    "labels = df['label'].as_matrix ()\n",
    "n = points.shape[0]\n",
    "d = points.shape[1]\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_centers(X, k):\n",
    "    sampling = np.random.randint(0, n, k)\n",
    "    return X[sampling, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast implementation of the distance matrix computation\n",
    "The idea is that $$||(x - c)||^2 = ||x||^2 -  2\\langle x, c \\rangle + ||c||^2 $$\n",
    "This has many advantages.\n",
    "1. The centers are fixed (during a single iteration), so only needs to compute once\n",
    "2. Data points are usually sparse, but centers are not\n",
    "3. If implement cleverly, we don't need to use for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_d2(X, centers):\n",
    "    D = np.empty((n, k))   \n",
    "    for i in range(n):\n",
    "        D[i, :] = np.linalg.norm(X[i,:] - centers, axis=1) ** 2\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_d2_fast(X, centers):\n",
    "\n",
    "    # @YOUSE: compute a length-n array, where each entry is the square of norm of a point\n",
    "    first_term = \n",
    "\n",
    "    # @YOUSE: compute a (n * k) matrix, where entry (i,j) is the two times of inner product of row i of X and row j of centers\n",
    "    second_term = \n",
    "\n",
    "    # @YOUSE: compute a length-k array, where each entry is the square of norm of a center\n",
    "    third_term = \n",
    "    \n",
    "    D = np.tile(first_term, (centers.shape[0], 1)).T - second_term + np.tile(third_term, (n,1))\n",
    "    D[D < 0] = 0\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the different in running time of the two implementations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = init_centers(points, k)\n",
    "%timeit D = compute_d2(points, centers)\n",
    "%timeit D = compute_d2_fast(points, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_points(D): \n",
    "    return np.argmin(D, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_centers(X, clustering):\n",
    "    centers = np.empty((k, d))\n",
    "    for i in range(k):\n",
    "        members = (clustering == i)\n",
    "        if any(members):\n",
    "            centers[i, :] = np.mean(X[members, :], axis=0)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def WCSS(D):\n",
    "    min_val = np.amin(D, axis=1)\n",
    "    return np.sum(min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_converged(old_centers, centers):\n",
    "    return set([tuple(x) for x in old_centers]) == set([tuple(x) for x in centers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans_basic(X, k):\n",
    "    old_centers = init_centers(X, k)\n",
    "    centers = init_centers(X, k)\n",
    "    i = 1\n",
    "    while not has_converged(old_centers, centers):\n",
    "        old_centers = centers\n",
    "        D = compute_d2_fast(X, centers)\n",
    "        clustering = cluster_points(D)\n",
    "        centers = update_centers(X, clustering)\n",
    "        print \"iteration\", i, \"WCSS = \", WCSS(D)\n",
    "        i += 1\n",
    "    return centers, clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers, clustering = kmeans_basic(points, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_clustering_k2(centers, clustering):\n",
    "    df['clustering'] = clustering\n",
    "    sns.lmplot(data=df, x=\"x_1\", y=\"x_2\", hue=\"clustering\", fit_reg=False,)\n",
    "    if df['clustering'][0] == 0:\n",
    "        colors = ['b', 'g']\n",
    "    else:\n",
    "        colors = ['g', 'b']\n",
    "    plt.scatter(centers[:,0], centers[:,1], s=500, c=colors, marker=u'*' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_clustering_k2(centers, clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means implementation in Scipy\n",
    "Actually, Python has a builtin K-means implementation in Scipy.\n",
    "\n",
    "Scipy is a superset of Numpy, and is installed by default in many Python distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans,vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# distortion is the same as WCSS.\n",
    "# It is called distortion in the Scipy document, since clustering can be used in compression.\n",
    "centers, distortion = kmeans(points, k)\n",
    "\n",
    "# vq return the clustering (assignment of group for each point)\n",
    "# based on the centers obtained by the kmeans function.\n",
    "# _ here means ignore the second return value\n",
    "clustering, _ = vq(points, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_clustering_k2(centers, clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow method to determine a good k\n",
    "Elbow method is a general rule of thumb when selecting parameters.\n",
    "\n",
    "The idea is to that one should choose a number of clusters so that adding another cluster doesn't give much better modeling of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_kcurve = pd.DataFrame(columns = ['k', 'distortion']) \n",
    "for i in range(1,10):\n",
    "    _, distortion = kmeans(points, i)\n",
    "    df_kcurve.loc[i] = [i, distortion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_kcurve.plot(x=\"k\", y=\"distortion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that at $k=2$, there is a sharper angle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: implement K-means++\n",
    "K-means++ differs from K-means only in the initialization step.\n",
    "\n",
    "In K-means, we randomly select k random data points as the centers at one time.\n",
    "One may have bad luck and get poor initializations where all k points are concentrated in one area.\n",
    "This could lead to a bad local optimum or take a long time to converge.\n",
    "\n",
    "\n",
    "The idea of K-means++ is to select more spread-out centers.\n",
    "In particular, K-means++ selects k centers iteratively, one at a time.\n",
    "In the first iteration, it randomly choose only one random points as the 1st center.\n",
    "In the second iteration, we calculate the square distance  between each point and the 1st center,\n",
    "and randomly choose the 2nd center with a probability distribution proportional to this square distance. \n",
    "Now suppose we have chosen $m<k$ centers, the $(m+1)$-th center is randomly chosen\n",
    "with a probability distribution proportional to the square distance between each point to its nearest center.\n",
    "The initialization step finishes when all k centers are chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_centers_kplusplus(X, k):\n",
    "    \n",
    "    # @YOUSE: implement the initialization step in k-means++ \n",
    "    # return centers: (k * d) matrix\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kmeans_kplusplus(X, k):\n",
    "    old_centers = init_centers_kplusplus(X, k)\n",
    "    centers = init_centers(X, k)\n",
    "    i = 1\n",
    "    while not has_converged(old_centers, centers):\n",
    "        old_centers = centers\n",
    "        D = compute_d2_fast(X, centers)\n",
    "        clustering = cluster_points(D)\n",
    "        centers = update_centers(X, clustering)\n",
    "        print \"iteration\", i, \"WCSS = \", WCSS(D)\n",
    "        i += 1\n",
    "    return centers, clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers, clustering = kmeans_kplusplus(points, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_clustering_k2(centers, clustering)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
