{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 6040, Fall 2015 [13]: PageRank (cont'd)\n",
    "\n",
    "> This notebook is identical to [Lab 12](http://nbviewer.ipython.org/github/rvuduc/cse6040-ipynbs/blob/master/12--pagerank.ipynb), but with solutions provided for Part 1.\n",
    "\n",
    "In this notebook, you'll implement the [PageRank algorithm](http://ilpubs.stanford.edu:8090/422/) summarized in class. You'll test it on a real dataset (circa 2005) that consists of [political blogs](http://networkdata.ics.uci.edu/data/polblogs/) and their links among one another.\n",
    "\n",
    "Note that the presentation in class follows the matrix view of the algorithm. Cleve Moler (inventor of MATLAB) has a nice set of notes [here](https://www.mathworks.com/moler/exm/chapters/pagerank.pdf).\n",
    "\n",
    "For today's notebook, you'll need to download the following additional materials:\n",
    "* A `cse6040utils` module, which is a Python module containing some handy routines from previous classes: [link](https://raw.githubusercontent.com/rvuduc/cse6040-ipynbs/master/cse6040utils.py) (Note: This module is already part of the `git` repo for our notebooks if you are pulling from there.)\n",
    "* A SQLite version of the political blogs dataset: http://cse6040.gatech.edu/fa15/poliblogs.db (~ 611 KiB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Explore the Dataset\n",
    "\n",
    "Let's start by looking at the dataset, to get a feel for what it contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidentally, one of you asked recently how to get the schema for a SQLite database when using Python. Here is some code adapted from a few ideas floating around on the web. Let's use these to inspect the tables available in the political blogs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vertices ===\n",
      "[0] index : INTEGER\n",
      "[1] Id : INTEGER\n",
      "[2] Url : TEXT\n",
      "[3] Leaning : TEXT\n",
      "\n",
      "\n",
      "   index  Id                         Url Leaning\n",
      "0      0   1        100monkeystyping.com    Left\n",
      "1      1   2  12thharmonic.com/wordpress    Left\n",
      "2      2   3       40ozblog.blogspot.com    Left\n",
      "3      3   4             4lina.tblog.com    Left\n",
      "4      4   5       750volts.blogspot.com    Left\n",
      "\n",
      "\n",
      "=== Edges ===\n",
      "[0] index : INTEGER\n",
      "[1] Source : INTEGER\n",
      "[2] Target : INTEGER\n",
      "\n",
      "\n",
      "   index  Source  Target\n",
      "0      0     267    1394\n",
      "1      1     267     483\n",
      "2      2     267    1051\n",
      "3      3     904    1479\n",
      "4      4     904     919\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sqlite3 as db\n",
    "import pandas as pd\n",
    "\n",
    "def get_table_names (conn):\n",
    "    assert type (conn) == db.Connection # Only works for sqlite3 DBs\n",
    "    query = \"SELECT name FROM sqlite_master WHERE type='table'\"\n",
    "    return pd.read_sql_query (query, conn)\n",
    "\n",
    "def print_schemas (conn, table_names=None, limit=0):\n",
    "    assert type (conn) == db.Connection # Only works for sqlite3 DBs\n",
    "    if table_names is None:\n",
    "        table_names = get_table_names (conn)\n",
    "    c = conn.cursor ()\n",
    "    query = \"PRAGMA TABLE_INFO ({table})\"\n",
    "    for name in table_names:\n",
    "        c.execute (query.format (table=name))\n",
    "        columns = c.fetchall ()\n",
    "        print (\"=== {table} ===\".format (table=name))\n",
    "        col_string = \"[{id}] {name} : {type}\"\n",
    "        for col in columns:\n",
    "            print (col_string.format (id=col[0],\n",
    "                                      name=col[1],\n",
    "                                      type=col[2]))\n",
    "        print (\"\\n\")\n",
    "\n",
    "conn = db.connect ('poliblogs.db')\n",
    "\n",
    "for name in get_table_names (conn)['name']:\n",
    "    print_schemas (conn, [name])\n",
    "    query = '''SELECT * FROM %s LIMIT 5''' % name\n",
    "    print (pd.read_sql_query (query, conn))\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Write a snippet of code to verify that the vertex IDs are _dense_ in some interval $[1, n]$. That is, there is a minimum value of $1$, some maximum value $n$, and _no_ missing values between $1$ and $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MinId  MaxId  NumDistinctIds\n",
      "0      1   1490            1490\n",
      "\n",
      "==> Verified: Vertex ids cover [1, 1490] densely.\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "  SELECT MIN(Id) AS MinId,\n",
    "         MAX(Id) AS MaxId,\n",
    "         COUNT(DISTINCT Id) AS NumDistinctIds\n",
    "    FROM Vertices\n",
    "'''\n",
    "df = pd.read_sql_query (query, conn)\n",
    "print df\n",
    "assert df.MinId[0] == 1\n",
    "assert df.MaxId[0] == df.NumDistinctIds[0]\n",
    "print (\"\\n==> Verified: Vertex ids cover [1, %d] densely.\" \\\n",
    "       % df.NumDistinctIds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Make sure every edge has its end points in the vertex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Source, dtype: object)\n",
      "Series([], Name: Target, dtype: object)\n",
      "==> Verified: All source and target IDs are vertices.\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "  SELECT {col} FROM Edges\n",
    "    WHERE {col} NOT IN (SELECT Id FROM Vertices)\n",
    "'''\n",
    "\n",
    "df_s = pd.read_sql_query (query.format (col='Source'), conn)\n",
    "print (df_s['Source'])\n",
    "\n",
    "df_t = pd.read_sql_query (query.format (col='Target'), conn)\n",
    "print (df_t['Target'])\n",
    "\n",
    "assert df_s['Source'].empty\n",
    "assert df_t['Target'].empty\n",
    "\n",
    "print (\"==> Verified: All source and target IDs are vertices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Determine which vertices have no incident edges. Store the number of such vertices in a variable, `num_solo_vertices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id                                   Url\n",
      "0   3                 40ozblog.blogspot.com\n",
      "1   4                       4lina.tblog.com\n",
      "2  25       americandreamslost.blogspot.com\n",
      "3  48  asian-nation.org/headlines/index.php\n",
      "4  49           asiegeofherons.blogspot.com\n",
      "\n",
      "==> 266 vertices have no incident edges.\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "  SELECT Id, Url\n",
    "    FROM Vertices\n",
    "    WHERE (Id NOT IN (SELECT DISTINCT Source FROM Edges))\n",
    "          AND (Id NOT IN (SELECT DISTINCT Target FROM Edges))\n",
    "'''\n",
    "df_solo_vertices = pd.read_sql_query (query, conn)\n",
    "print df_solo_vertices.head ()\n",
    "\n",
    "num_solo_vertices = len (df_solo_vertices)\n",
    "\n",
    "# Our testing code follows, assuming your `num_solo_vertices` variable:\n",
    "print (\"\\n==> %d vertices have no incident edges.\" % num_solo_vertices)\n",
    "assert num_solo_vertices == 266"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Compute a view called `Outdegrees`, which contains the following columns:\n",
    "\n",
    "1. `Id`: vertex ID\n",
    "2. `Degree`: the out-degree of this vertex.\n",
    "\n",
    "To help you test your view, the following snippet includes a second query that selects from your view but adds a Url field and orders the results in descending order of degree. It also prints first few and last few rows of this query, so you can inspect the URLs as a sanity check. (Perhaps it also provides a small bit of entertainment!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x106d5cce0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete this query:\n",
    "query = '''\n",
    "  CREATE VIEW IF NOT EXISTS Outdegrees AS\n",
    "    SELECT Source AS Id, COUNT(*) AS Degree\n",
    "      FROM Edges\n",
    "      GROUP BY Source\n",
    "'''\n",
    "c = conn.cursor ()\n",
    "c.execute (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> A few entries with large out-degrees:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>855</td>\n",
       "      <td>256</td>\n",
       "      <td>blogsforbush.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>454</td>\n",
       "      <td>140</td>\n",
       "      <td>newleftblogs.blogspot.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>387</td>\n",
       "      <td>131</td>\n",
       "      <td>madkane.com/notable.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>131</td>\n",
       "      <td>politicalstrategy.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>880</td>\n",
       "      <td>123</td>\n",
       "      <td>cayankee.blogs.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Degree                        Url\n",
       "0  855     256           blogsforbush.com\n",
       "1  454     140  newleftblogs.blogspot.com\n",
       "2  387     131   madkane.com/notable.html\n",
       "3  512     131      politicalstrategy.org\n",
       "4  880     123         cayankee.blogs.com"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==> A few entries with small out-degrees:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>1468</td>\n",
       "      <td>1</td>\n",
       "      <td>watchandwait.blogspot.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1481</td>\n",
       "      <td>1</td>\n",
       "      <td>writehouse.us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1486</td>\n",
       "      <td>1</td>\n",
       "      <td>youngconservative.blogspot.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1488</td>\n",
       "      <td>1</td>\n",
       "      <td>zeke01.blogspot.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>1490</td>\n",
       "      <td>1</td>\n",
       "      <td>zeph1z.tripod.com/blog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  Degree                             Url\n",
       "1060  1468       1       watchandwait.blogspot.com\n",
       "1061  1481       1                   writehouse.us\n",
       "1062  1486       1  youngconservative.blogspot.com\n",
       "1063  1488       1             zeke01.blogspot.com\n",
       "1064  1490       1          zeph1z.tripod.com/blog"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "query = '''\n",
    "  SELECT Outdegrees.Id, Degree, Url\n",
    "    FROM Outdegrees, Vertices\n",
    "    WHERE Outdegrees.Id = Vertices.Id\n",
    "    ORDER BY -Degree\n",
    "'''\n",
    "df_outdegrees = pd.read_sql_query (query, conn)\n",
    "print \"==> A few entries with large out-degrees:\"\n",
    "display (df_outdegrees.head ())\n",
    "print \"\\n==> A few entries with small out-degrees:\"\n",
    "display (df_outdegrees.tail ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Query the database to extract a report of which URLs point to which URLs. Also include the source vertex out-degree and order the rows in descending order by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.Url</th>\n",
       "      <th>T.Url</th>\n",
       "      <th>Out.Degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blogsforbush.com</td>\n",
       "      <td>ibe.blogspot.com</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blogsforbush.com</td>\n",
       "      <td>aceoftrumpblog.blogspot.com</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blogsforbush.com</td>\n",
       "      <td>achicknamedmarzi.com</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blogsforbush.com</td>\n",
       "      <td>alamonation.blogspot.com</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blogsforbush.com</td>\n",
       "      <td>alarmingnews.com</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              S.Url                        T.Url  Out.Degree\n",
       "0  blogsforbush.com             ibe.blogspot.com         256\n",
       "1  blogsforbush.com  aceoftrumpblog.blogspot.com         256\n",
       "2  blogsforbush.com         achicknamedmarzi.com         256\n",
       "3  blogsforbush.com     alamonation.blogspot.com         256\n",
       "4  blogsforbush.com             alarmingnews.com         256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.Url</th>\n",
       "      <th>T.Url</th>\n",
       "      <th>Out.Degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19085</th>\n",
       "      <td>watchandwait.blogspot.com</td>\n",
       "      <td>freerepublic.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19086</th>\n",
       "      <td>writehouse.us</td>\n",
       "      <td>realclearpolitics.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19087</th>\n",
       "      <td>youngconservative.blogspot.com</td>\n",
       "      <td>blogsforbush.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19088</th>\n",
       "      <td>zeke01.blogspot.com</td>\n",
       "      <td>zeke01.typepad.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19089</th>\n",
       "      <td>zeph1z.tripod.com/blog</td>\n",
       "      <td>anncoulter.org</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                S.Url                  T.Url  Out.Degree\n",
       "19085       watchandwait.blogspot.com       freerepublic.com           1\n",
       "19086                   writehouse.us  realclearpolitics.com           1\n",
       "19087  youngconservative.blogspot.com       blogsforbush.com           1\n",
       "19088             zeke01.blogspot.com     zeke01.typepad.com           1\n",
       "19089          zeph1z.tripod.com/blog         anncoulter.org           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = '''\n",
    "  SELECT S.Url, T.Url, Out.Degree\n",
    "    FROM Edges AS E,\n",
    "         (SELECT Id, Url FROM Vertices) AS S,\n",
    "         (SELECT Id, Url FROM Vertices) AS T,\n",
    "         (SELECT Id, Degree FROM Outdegrees) AS Out\n",
    "    WHERE (E.Source=S.Id) AND (E.Target=T.Id) AND (E.Source=Out.Id)\n",
    "    ORDER BY -Out.Degree\n",
    "'''\n",
    "df_G = pd.read_sql_query (query, conn)\n",
    "\n",
    "from IPython.display import display\n",
    "display (df_G.head ())\n",
    "print (\"...\")\n",
    "display (df_G.tail ())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement PageRank\n",
    "\n",
    "The following exercises will walk you through a possible implementation of PageRank for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Build a sparse matrix, `A_1`, that stores $G^TD^{-1}$, where $G^T$ is the transpose of the connectivity matrix $G$, and $D^{-1}$ is the diagonal matrix of inverse out-degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cse6040utils import sparse_matrix\n",
    "\n",
    "A_1 = sparse_matrix () # Initially all zeros, with no rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Implement a function to multiply a sparse matrix by a dense vector, assuming a dense vector defined as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dense_vector (n, init_val=0.0):\n",
    "    \"\"\"\n",
    "    Returns a dense vector of length `n`, with all entries set to\n",
    "    `init_val`.\n",
    "    \"\"\"\n",
    "    return [init_val] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Implement this routine:\n",
    "def spmv (n, A, x):\n",
    "    \"\"\"Returns a dense vector y of length n, where y = A*x.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Complete the PageRank implementation for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_vector (x, alpha):\n",
    "    \"\"\"Scales the dense vector x by a constant alpha.\"\"\"\n",
    "    return [x_i*alpha for x_i in x]\n",
    "\n",
    "def offset_vector (x, c):\n",
    "    \"\"\"Adds the scalar value c to every element of a dense vector x.\"\"\"\n",
    "    return [x_i+c for x_i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALPHA = 0.85 # Probability of following some link\n",
    "MAX_ITERS = 25\n",
    "\n",
    "# Let X[t] store the dense x(t) vector at time t\n",
    "X = []\n",
    "\n",
    "x_0 = dense_vector (n, 1.0/n) # Initial distribution: 1/n at each page\n",
    "X.append (x_0)\n",
    "\n",
    "for t in range (1, MAX_ITERS):\n",
    "    # Complete this implementation\n",
    "    \n",
    "    X.append (...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** Check your result by first inserting the _final_ computed PageRank vector back into the database, and then using a SQL query to see the ranked URLs. In your query output, also include _both_ the in-degrees and out-degrees of each vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  CREATE VIEW IF NOT EXISTS Indegrees AS\n",
    "    SELECT Target AS Id, COUNT(*) AS Degree\n",
    "      FROM Edges\n",
    "      GROUP BY Target\n",
    "'''\n",
    "c = conn.cursor ()\n",
    "c.execute (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Complete this query:\n",
    "query = '''\n",
    "  ...\n",
    "'''\n",
    "df_ranks = pd.read_sql_query (query, conn)\n",
    "display (df_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise.** The `Vertices` table includes a column called, `Leaning`, which expresses a political leaning -- either \"Left\" or \"Right\". How might you use this column to come up with an alternative ranking scheme?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise (advanced?).** Create an SQL-based implementation of the PageRank algorithm, where you implement the sparse matrix-vector multiply in SQL, rather than in Python as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
