{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 4: Video Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This problem revisits image compression but asks how to extend to video. Remember how we used the idea of a low rank approximation of a matrix to compress an image. In this notebook, we will extend the same idea to a video. A video for our purpose is just an ordered sequence of images/matrices. To compress a video, we need to compress each of the frames by finding its lower rank approximation using the SVD. Apart from this, you will be implementing a second way (Average Pooling) to compress an image/video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will first read in a flattened 2D array, in which each row is a frame in the video. You will be required to reshape this flattened 2D array to a 3D array for the video. After that, you will work on compressing this video by two alternate methods -\n",
    "1. SVD (lower rank approximation) \n",
    "2. Average pooling. \n",
    "\n",
    "Note: We will be using the term 3D array/tensor interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CATALYST_LOG_LEVEL=15\n"
     ]
    }
   ],
   "source": [
    "# Importing dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook  \n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from IPython.display import HTML\n",
    "import imageio\n",
    "import warnings\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "%env CATALYST_LOG_LEVEL = 15 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The cell below reads in the flattened version of the matrix. Run the cell below to load the matrix and read the following statements carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The matrix M has 61 rows and 921600 columns\n"
     ]
    }
   ],
   "source": [
    "v = np.load('../resource/asnlib/publicdata/video.npz')\n",
    "M = v[\"arr_0\"]\n",
    "M = M.astype(np.int32)\n",
    "row, col = M.shape\n",
    "print(\"The matrix M has {} rows and {} columns\".format(row, col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Each of the 61 rows in `M` is a frame in the video. Each row has to be converted to a 2D array to visualize it as a frame. The flattening uses a C-language order (i.e., row major) and has to be restored as a 2D array. Each frame is originally 720 x 1280 in shape. The sequence of rows in `M` is the same as the sequence of frames in the video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Your first task is to extract each row from this flattened array `M` and store it as a 2D array of size 720 x 1280. The 2D arrays are then stacked together to form a tensor of size 61 x 720 x 1280."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 0** (1 point). Write some code that extracts the video from the flattened matrix and stores it in the variable **`vid`**. Your output should be a tensor of shape 61 x 720 x 1280. Remember that the original rows in the matrix `M` were saved in a C-type format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "reshape_test",
     "locked": false,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This is not a function but a code snippet.\n",
    "# Your output of size 61 x 720 x 1280 should be stored in the variable vid. \n",
    "vid = None\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "reshape_test",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-33c76dcade50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Test cell - reshape_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m61\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1280\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"The shapes are incorrect\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvid_flattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvid_flattened\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Test cell - reshape_test\n",
    "f, r, c = vid.shape\n",
    "assert (f, r, c) == (61, 720, 1280), \"The shapes are incorrect\"\n",
    "vid_flattened = np.reshape(vid, (f, r*c), \"C\")\n",
    "err = M - vid_flattened\n",
    "err_norm = np.linalg.norm(err, 'fro')\n",
    "assert err_norm <= 1e-8, \"Incorrect values\"\n",
    "del err, M, vid_flattened\n",
    "print(\"Passed!\")\n",
    "vidx = vid.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Running the cell below displays content of the original video. You can comment this out if this cell increases your run time. The code in this cell helps you see the video in the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vidx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-725b156d26d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# submitting to the autograder as it may increase your total running time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'original.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"<video width=\"480\" height=\"360\" controls>   <source src=\"{0}\"> </video> \"\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./original.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vidx' is not defined"
     ]
    }
   ],
   "source": [
    "# The code in this cell shows the original video. You can comment out this part while \n",
    "# submitting to the autograder as it may increase your total running time.\n",
    "warnings.simplefilter('ignore')\n",
    "imageio.mimwrite('original.mp4', vidx, fps=30)\n",
    "HTML(\"\"\"<video width=\"480\" height=\"360\" controls>   <source src=\"{0}\"> </video> \"\"\".format('./original.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We hope that the video above helped you realize that a sequence of 2D arrays, each of which is an image, can represent a video. In the next exercise, you will apply SVD to each of the constituent frames of the image to compress the complete video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## SVD review\n",
    "For a quick review of SVD and how this is used to compress images/videos, refer to [this](http://theory.stanford.edu/~tim/s15/l/l9.pdf) discussion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 1** (2 points). Complete the function, **`svd_approx(m, r)`**, where **`m`** is a 2D Numpy array and **`r`** is a scalar rank. This function should return a new matrix, which is the same size as **`m`**, that stores the best rank **`r`** approximation of **`m`** (as measured by the Frobenius norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def svd_approx(m, r):\n",
    "    U, D, V = np.linalg.svd(m, full_matrices=True)\n",
    "    return U\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "svd_test",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3007188   0.07285743 -0.48184901 -0.32086158 -0.35893065  0.41734905\n",
      "   0.47650759 -0.19763212]\n",
      " [-0.3243702   0.51303749  0.44053002 -0.10079233  0.5349735   0.15246143\n",
      "   0.33738004 -0.06390844]\n",
      " [-0.45922541 -0.04592178  0.30115483  0.47010612 -0.3117484   0.3840021\n",
      "  -0.36319753 -0.31424846]\n",
      " [-0.39902008 -0.30517488  0.40042528 -0.55968131 -0.24162546 -0.07617603\n",
      "  -0.10771331  0.44528629]\n",
      " [-0.24197195  0.49892144 -0.40585818 -0.27615578  0.10105768 -0.09431798\n",
      "  -0.65720651  0.02269713]\n",
      " [-0.32135495 -0.59318838 -0.19861178 -0.13044092  0.53912772 -0.11496646\n",
      "  -0.0697789  -0.42385374]\n",
      " [-0.43340303  0.14049204 -0.08543701  0.28117499 -0.23589808 -0.75753075\n",
      "   0.27142413 -0.05378791]\n",
      " [-0.29084285 -0.12534248 -0.33354643  0.42462877  0.26996844  0.23097375\n",
      "   0.07169433  0.69048171]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (8,6) (8,8) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-7aa16587a349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0merr_fro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_fro\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Incorrect\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Passed!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (8,6) (8,8) "
     ]
    }
   ],
   "source": [
    "# Test cell - svd_test\n",
    "for _ in range(5):\n",
    "    x = np.random.rand(8, 6)\n",
    "    l = np.random.randint(1,6)\n",
    "    x_l = svd_approx(x, l)\n",
    "    u, s, v = np.linalg.svd(x, False)\n",
    "    err = sum(s[l:]**2)**.5\n",
    "    err_fro = np.linalg.norm(x-x_l, 'fro')\n",
    "    assert abs(err_fro - err) <= 1e-8, \"Incorrect\"\n",
    "print(\"Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 2** (2 points). Complete the function **`compress_vid`**(`vid`, `r`), below. This function takes two inputs, a 3D array **`vid`** (like the `vid` array above) and a scalar **`r`**. It should compute the best rank-`r` approximation of each frame in the input array and returns a new 3D array, which is of the same shape as the input `vid`, where each frame of the output is the best rank-`r` approximation of its corresponding input frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compress_vid(vid, r):\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "vid_compress_test",
     "locked": true,
     "points": "2",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Cell - vid_compress_test\n",
    "# The values have been converted to an int type because they require 8 times less memory than float values. \n",
    "# Important: \n",
    "# This test cell will be only run at the time of submission. Please use the code to display the compressed video\n",
    "# in the next cell to verify your correctness. Remember you can submit as many times as you want. \n",
    "\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Running the cell below displays content of the video compressed by using SVD. \n",
    "\n",
    "**Note**: We suggest you comment this out if this cell increases your run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Running this cell shows the video. \n",
    "# You can comment out this part if you wish as it can increase your total test time during submission.\n",
    "# The white spots in the video are due to the uint approximation.\n",
    "\n",
    "# Important: \n",
    "# Make sure you comment this section before submitting as the runtime for this cell exceeds the time limit. \n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "cmpr_svd = compress_vid(vid, 15)\n",
    "cmpr_svd_uint = cmpr_svd.astype(np.uint8)\n",
    "imageio.mimwrite('cmpr_svd.mp4', cmpr_svd_uint, fps=30)\n",
    "HTML(\"\"\"<video width=\"480\" height=\"360\" controls>   <source src=\"{0}\"> </video> \"\"\".format('./cmpr_svd.mp4'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Average Pooling\n",
    "\n",
    "Now we will see a different way of approaching the compression problem. By using SVD, we had retained the shape of the array. In this part of the notebook, you will be required to compress the image such that its shape is reduced, but the spatial pattern remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The shape of each frame is 720 x 1280. There are 720 rows and 1280 columns. Now, imagine that the matrix has been divided in non-overlapping 2x2 matrices. Hence there will be 360 x 640 smaller matrices placed across the original matrix such that they are all adjacent to each other and do not overlap. Read the following cells for a better understanding.\n",
    "\n",
    "Imagine that the original image **`original_im`** was a 4 x 10 matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original array (image) is: \n",
      "\n",
      "[[1 2 2 1 4 6 0 1 2 3]\n",
      " [1 8 7 5 4 2 4 2 4 3]\n",
      " [3 7 1 3 0 9 8 5 3 1]\n",
      " [2 1 2 4 6 4 3 1 2 5]]\n"
     ]
    }
   ],
   "source": [
    "original_im = np.array([[1,2,2,1,4,6,0,1,2,3],\n",
    "                        [1,8,7,5,4,2,4,2,4,3],\n",
    "                        [3,7,1,3,0,9,8,5,3,1],\n",
    "                        [2,1,2,4,6,4,3,1,2,5]])\n",
    "print(\"The original array (image) is: \\n\")\n",
    "print(original_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now suppose one divides the original array into small blocks, or **tiles**, of size 2 x 2 each. The **`mask`** array below logically encodes one such example of a \"tiling.\" Run this cell to print it, and then we will describe its format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2 x 2 masks over the original array are: \n",
      "\n",
      "[[0 0 1 1 2 2 3 3 4 4]\n",
      " [0 0 1 1 2 2 3 3 4 4]\n",
      " [5 5 6 6 7 7 8 8 9 9]\n",
      " [5 5 6 6 7 7 8 8 9 9]]\n"
     ]
    }
   ],
   "source": [
    "a = [0,0,1,1,2,2,3,3,4,4]\n",
    "b = [5,5,6,6,7,7,8,8,9,9]\n",
    "mask = np.array([a,a,b,b])\n",
    "print(\"The 2 x 2 masks over the original array are: \\n\")\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that `mask` is the same size as the original image. It effectively divides the original image into a grid of 2 x 5 = 10 tiles, numbered from 0 to 9 inclusive, where each tile is 2 x 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In our alternative compression scheme, we will \"pool\" each tile. That is, given an image, we will replace each tile of the original image with a single value. That value is the average of values within the tile.\n",
    "\n",
    "For instance, consider the tile numbered 2 in the above mask. It corresponds to the following submatrix of the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== mask[0:2, 4:6] ===\n",
      "[[2 2]\n",
      " [2 2]]\n",
      "=== original_im[0:2, 4:6] ===\n",
      "[[4 6]\n",
      " [4 2]]\n",
      "=== average in this tile ===\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(\"=== mask[0:2, 4:6] ===\")\n",
    "print(mask[0:2, 4:6])\n",
    "print(\"=== original_im[0:2, 4:6] ===\")\n",
    "print(original_im[0:2, 4:6])\n",
    "print(\"=== average in this tile ===\")\n",
    "print(original_im[0:2, 4:6].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If we were to pool every tile, here is what the final result would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Recall: The original image:\\n{}\".format(original_im))\n",
    "\n",
    "mask_avg = np.array([[12, 15, 16, 7, 12],\n",
    "                    [13, 10, 19, 17, 11]])/4\n",
    "print(\"\\nThe average pooled array is:\\n{}\".format(mask_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In Exercise 3, below, you will implement the average pooling procedure. Here are some hints on one way to approach the problem.\n",
    "\n",
    "1. We advise against using loops to implement an element-by-element approach. Such a method is likely to take a long time and the test cells may time out.\n",
    "2. One idea might be to use a linear (matrix) transformation: is there a matrix **`A`**, such that `A` times `original_im` is `mask_avg`?\n",
    "3. In a linear transformation-based (or matrix multiply-based) approach, `A` might be sparse and the process might involve reshaping `original_im` and reshaping back to get `mask_avg`.\n",
    "\n",
    "Following these hints is not the only way of solving this problem. You are free to use any approach that is correct and passes the autograder. (But if the autograder times out, you'll get no credit, so proceed with caution!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Exercise 3** (5 points). Complete the function **`avg_pooled`**`(vid)`, below. It takes as input the original video as a 3-D array (tensor) of shape $f \\times r \\times c$. (In our video example, this shape is 61 x 720 x 1280.) Your function should assume $2 \\times 2$ tiles and, accordingly, return an average pooled tensor of shape $f \\times \\dfrac{r}{2} \\times \\dfrac{c}{2}$ (61 x 360 x 640). Assume that $r$ and $c$ are known to be even numbers. \n",
    "\n",
    "To explain it again, each frame in the original video that was of size 720 x 1280 should be average pooled to the size 360 x 640, taking averages within the 2 x 2 tiles of the original in produce the output. This procedure has to be done for all frames and the final video returned by the function should be a tensor of size 61 x 360 x 640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_pooled(vid):\n",
    "    #\n",
    "    # YOUR CODE HERE\n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "pooling_test",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cell - pooling_test\n",
    "# Test and prepare for display. The type has been changed to np.uint8 for ease of display in the notebook.\n",
    "\n",
    "# Important: \n",
    "# This test cell will be only run at the time of submission. Please use the code to display the compressed video\n",
    "# in the next cell to verify your correctness. Remember you can submit as many times as you want. \n",
    "\n",
    "#\n",
    "# AUTOGRADER TEST - DO NOT REMOVE\n",
    "#\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Running the cell below displays content of the video compressed by average pooling. You can comment this out if this cell increases your run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running this cell shows the video. \n",
    "# You can comment out this part if you wish as it can increase your total test time during submission.\n",
    "\n",
    "# Important: \n",
    "# Make sure you comment this section before submitting as the runtime for this cell exceeds the time limit. \n",
    "\n",
    "cmpr_pooled = avg_pooled(vid)\n",
    "cmpr_pooled_uint = cmpr_pooled.astype(np.uint8)\n",
    "warnings.simplefilter('ignore')\n",
    "imageio.mimwrite('cmpr_pooled.mp4', cmpr_pooled_uint, fps=30)\n",
    "HTML(\"\"\"<video width=\"480\" height=\"380\" controls>   <source src=\"{0}\"> </video> \"\"\".format('./cmpr_pooled.mp4'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "You can see that even though the output of the average pooled case looks very similar to the original video, the tensor in the average pooled case was 1/4 in size of the original tensor. You can use the average pooling function repeatedly to compress the tensor and after a couple of such compression stages, the difference will be more significant. The code for that has been left in the comments below, if you would like to try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Sample code to try multi stage pooling compression. \n",
    "# Repeated pooling can help achieve greater reductions in frame sizes.\n",
    "# You can comment out this part as it will not be graded. It is for demonstrative purposes only.\n",
    "# \"\"\"\n",
    "# for _ in range(3):\n",
    "#     cmpr_pooled = avg_pooled(cmpr_pooled)\n",
    "# print(\"Shape of final tensor : {}\".format(cmpr_pooled.shape))\n",
    "# cmpr_pooled = cmpr_pooled.astype(np.uint8)\n",
    "# warnings.simplefilter('ignore')\n",
    "# imageio.mimwrite('multi_compression.mp4', cmpr_pooled, fps=30)\n",
    "# HTML(\"\"\"<video width=\"480\" height=\"380\" controls>   <source src=\"{0}\"> </video> \"\"\".format('./multi_compression.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Fin!** Remember to test your solutions by running them as the autograder will: restart the kernel and run all cells from \"top-to-bottom.\" Also remember to submit to the autograder; otherwise, you will **not** get credit for your hard work!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
