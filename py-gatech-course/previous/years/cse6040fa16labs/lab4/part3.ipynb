{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "# Important note!\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR_ID = \"\" # Please enter your GT login, e.g., \"rvuduc3\" or \"gtg911x\"\n",
    "COLLABORATORS = [] # list of strings of your collaborators' IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b11295002cc2b9549d6a2b01721b6701",
     "grade": true,
     "grade_id": "who__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_CHECK_ID = re.compile (r'''[a-zA-Z]+\\d+|[gG][tT][gG]\\d+[a-zA-Z]''')\n",
    "assert RE_CHECK_ID.match (YOUR_ID) is not None\n",
    "\n",
    "collab_check = [RE_CHECK_ID.match (i) is not None for i in COLLABORATORS]\n",
    "assert all (collab_check)\n",
    "\n",
    "del collab_check\n",
    "del RE_CHECK_ID\n",
    "del re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter / IPython version check.** The following code cell verifies that you are using the correct version of Jupyter/IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Tibbles and Bits (35 points)\n",
    "\n",
    "Now let's start creating and manipulating tibbles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # The suggested idiom\n",
    "from io import StringIO\n",
    "\n",
    "from IPython.display import display # For pretty-printing data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (5 points). Write a function that, given a tibble, returns a new copy in _canonical order_. A tibble, `X`, is in canonical order has the following properties.\n",
    "\n",
    "1. The variables appear in sorted order by name, ascending from left to right.\n",
    "2. The rows appear in lexicographically sorted order by variable, ascending from top to bottom.\n",
    "3. The row labels (`X.index`) go from 0 to `n-1`, where `n` is the number of observations.\n",
    "\n",
    "For instance, here is a **non-canonical tibble** ...\n",
    "\n",
    "|   |  c  | a | b |\n",
    "|:-:|:---:|:-:|:-:|\n",
    "| 2 | hat | x | 1 |\n",
    "| 0 | rat | y | 4 |\n",
    "| 3 | cat | x | 2 |\n",
    "| 1 | bat | x | 2 |\n",
    "\n",
    "\n",
    "... and here is its **canonical counterpart.**\n",
    "\n",
    "|   | a | b |  c  |\n",
    "|:-:|:-:|:-:|:---:|\n",
    "| 0 | x | 1 | hat |\n",
    "| 1 | x | 2 | bat |\n",
    "| 2 | x | 2 | cat |\n",
    "| 3 | y | 4 | rat |\n",
    "\n",
    "A partial solution appears below, which ensures that Property 1 above holds. Complete the solution to ensure Properties 2 and 3 hold. Feel free to consult the [Pandas API](http://pandas.pydata.org/pandas-docs/stable/api.html).\n",
    "\n",
    "> **Hint**. For Property 3, you may find this function handy: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.set_index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6be8ca23ee3b6f9a16dc995ada44abd4",
     "grade": false,
     "grade_id": "canonicalize",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def canonicalize_tibble (X):\n",
    "    \"\"\"Returns a tibble in _canonical order_.\"\"\"\n",
    "    # Enforce Property 1:\n",
    "    var_names = sorted (X.columns)\n",
    "    Y = X[var_names].copy ()\n",
    "    \n",
    "    # Your turn: Enforce Properties 2 and 3 of canonical order!\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6633c507eb7aabdab7eb21cf9d3b0a76",
     "grade": true,
     "grade_id": "canonicalize__test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test input\n",
    "canonical_in_csv = \"\"\",c,a,b\n",
    "2,hat,x,1\n",
    "0,rat,y,4\n",
    "3,cat,x,2\n",
    "1,bat,x,2\"\"\"\n",
    "\n",
    "with StringIO (canonical_in_csv) as fp:\n",
    "    canonical_in = pd.read_csv (fp, index_col=0)\n",
    "print (\"=== Input ===\")\n",
    "display (canonical_in)\n",
    "print (\"\")\n",
    "    \n",
    "# Test output solution\n",
    "canonical_soln_csv = \"\"\",a,b,c\n",
    "0,x,1,hat\n",
    "1,x,2,bat\n",
    "2,x,2,cat\n",
    "3,y,4,rat\"\"\"\n",
    "\n",
    "with StringIO (canonical_soln_csv) as fp:\n",
    "    canonical_soln = pd.read_csv (fp, index_col=0)\n",
    "print (\"=== True solution ===\")\n",
    "display (canonical_soln)\n",
    "print (\"\")\n",
    "\n",
    "canonical_out = canonicalize_tibble (canonical_in)\n",
    "print (\"=== Your computed solution ===\")\n",
    "display (canonical_out)\n",
    "print (\"\")\n",
    "\n",
    "canonical_matches = (canonical_out == canonical_soln)\n",
    "print (\"=== Matches? (Should be all True) ===\")\n",
    "display (canonical_matches)\n",
    "assert canonical_matches.all ().all ()\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.** (5 points) Write a function to determine if two tibbles, stored as Pandas data frames, are equivalent. That means they have identical variables and observations, up to permutations.\n",
    "\n",
    "The last condition, \"up to permutations,\" means that the variables and observations might not appear in the table in the same order. For example, the following two tibbles are equivalent:\n",
    "\n",
    "| a | b |  c  |\n",
    "|:-:|:-:|:---:|\n",
    "| x | 1 | hat |\n",
    "| y | 2 | cat |\n",
    "| z | 3 | bat |\n",
    "| w | 4 | rat |\n",
    "\n",
    "| b |  c  | a |\n",
    "|:-:|:---:|:-:|\n",
    "| 2 | cat | y |\n",
    "| 3 | bat | z |\n",
    "| 1 | hat | x |\n",
    "| 4 | rat | w |\n",
    "\n",
    "By contrast, the following table would not be equivalent to either of the above tibbles.\n",
    "\n",
    "| a | b |  c  |\n",
    "|:-:|:-:|:---:|\n",
    "| 2 | y | cat |\n",
    "| 3 | z | bat |\n",
    "| 1 | x | hat |\n",
    "| 4 | w | rat |\n",
    "\n",
    "> **Note**: Unlike Pandas data frames, tibbles conceptually do not have row labels. So you should ignore row labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "cab10694a4b8cf72410b6c7934770913",
     "grade": false,
     "grade_id": "tibble_cmp",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tibbles_are_equivalent (A, B):\n",
    "    \"\"\"Given two tidy tables ('tibbles'), returns True iff they are\n",
    "    equivalent.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e658c90a09bbfe0d295b5a68515f13fa",
     "grade": true,
     "grade_id": "tibble_cmp__test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test code\n",
    "A = pd.DataFrame (columns=['a', 'b', 'c'],\n",
    "                  data=list (zip (['x', 'y', 'z', 'w'],\n",
    "                                  [1, 2, 3, 4],\n",
    "                                  ['hat', 'cat', 'bat', 'rat'])))\n",
    "print (\"=== Tibble A ===\")\n",
    "display (A)\n",
    "\n",
    "# Permute rows and columns, preserving equivalence\n",
    "import random\n",
    "\n",
    "obs_ind_orig = list (range (A.shape[0]))\n",
    "var_names = list (A.columns)\n",
    "\n",
    "obs_ind = obs_ind_orig.copy ()\n",
    "while obs_ind == obs_ind_orig:\n",
    "    random.shuffle (obs_ind)\n",
    "    \n",
    "while var_names == list (A.columns):\n",
    "    random.shuffle (var_names)\n",
    "\n",
    "B = A[var_names].copy ()\n",
    "B = B.iloc[obs_ind]\n",
    "\n",
    "print (\"=== Tibble B == A ===\")\n",
    "display (B)\n",
    "\n",
    "print (\"=== Tibble C != A ===\")\n",
    "C = A.copy ()\n",
    "C.columns = var_names\n",
    "display (C)\n",
    "\n",
    "assert tibbles_are_equivalent (A, B)\n",
    "assert not tibbles_are_equivalent (A, C)\n",
    "assert not tibbles_are_equivalent (B, C)\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melting\n",
    "\n",
    "Recall the melting operation.\n",
    "\n",
    "![Melt example](http://r4ds.had.co.nz/images/tidy-9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To melt the table, you need to do the following.\n",
    "\n",
    "1. Extract the _column values_ into a new variable. In this case, columns `\"1999\"` and `\"2000\"` of `table4` need to become the values of the variable, `\"year\"`.\n",
    "2. Convert the values associated with the column values into a new variable as well. In this case, the values formerly in columns `\"1999\"` and `\"2000\"` become the values of the `\"cases\"` variable.\n",
    "\n",
    "In the context of a melt, let's also refer to `\"year\"` as the new _key_ variable and `\"cases\"` as the new _value_ variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.** (5 points) Implement a melting function. It should take as arguments the input data frame (e.g., `table4`), a list of the column values, and names for the new columns.\n",
    "\n",
    "> You may need to refer to the Pandas documentation to figure out how to create and manipulate tables. The bits related to [indexing](http://pandas.pydata.org/pandas-docs/stable/indexing.html) and [merging](http://pandas.pydata.org/pandas-docs/stable/merging.html) may be especially helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "08fb27b8a52e3c4decd1cd3c9ebd3b4f",
     "grade": false,
     "grade_id": "melt",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def melt (df, col_vals, key, value):\n",
    "    assert type (df) is pd.DataFrame\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bf0e06c15a846829d77856545efd4a03",
     "grade": true,
     "grade_id": "melt_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "table4a = pd.read_csv ('table4a.csv')\n",
    "print (\"\\n=== table4a ===\")\n",
    "display (table4a)\n",
    "\n",
    "m_4a = melt (table4a, col_vals=['1999', '2000'], key='year', value='cases')\n",
    "print (\"=== melt (table4a) ===\")\n",
    "display (m_4a)\n",
    "\n",
    "table4b = pd.read_csv ('table4b.csv')\n",
    "print (\"\\n=== table4b ===\")\n",
    "display (table4b)\n",
    "\n",
    "m_4b = melt (table4b, col_vals=['1999', '2000'], key='year', value='population')\n",
    "print (\"=== melt (table4b) ===\")\n",
    "display (m_4b)\n",
    "\n",
    "m_4 = pd.merge (m_4a, m_4b, on=['country', 'year'])\n",
    "print (\"\\n=== inner-join (melt (table4a), melt (table4b)) ===\")\n",
    "display (m_4)\n",
    "\n",
    "m_4['year'] = m_4['year'].apply (int)\n",
    "\n",
    "table1 = pd.read_csv ('table1.csv')\n",
    "print (\"=== table1 (target solution) ===\")\n",
    "display (table1)\n",
    "assert tibbles_are_equivalent (table1, m_4)\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Casting\n",
    "\n",
    "Now recall the casting example:\n",
    "\n",
    "![Cast example](http://r4ds.had.co.nz/images/tidy-8.png)\n",
    "\n",
    "The signature of a cast is similar to that of melt. However, you only need to know the `key`, which is column of the input table containing new variable names, and the `value`, which is the column containing corresponding values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (5 points). Implement a function to cast a data frame into a tibble, given a key column containing new variable names and a value column containing the corresponding cells.\n",
    "\n",
    "We've given you a partial solution that\n",
    "\n",
    "- verifies that the given `key` and `value` columns are actual columns of the input data frame;\n",
    "- computes the list of columns, `fixed_vars`, that should remain unchanged; and\n",
    "- initializes and empty tibble.\n",
    "\n",
    "Observe that we are asking your `cast()` to accept an optional parameter, `join_how`, that may take the values `'outer'` or `'inner'` (with `'outer'` as the default). Why do you need such a parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "4b13ef569014c2c21302471650bf9bef",
     "grade": false,
     "grade_id": "cast",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cast (df, key, value, join_how='outer'):\n",
    "    \"\"\"Casts the input data frame into a tibble,\n",
    "    given the key column and value column.\n",
    "    \"\"\"\n",
    "    assert type (df) is pd.DataFrame\n",
    "    assert key in df.columns and value in df.columns\n",
    "    assert join_how in ['outer', 'inner']\n",
    "    \n",
    "    fixed_vars = df.columns.difference ([key, value])\n",
    "    tibble = pd.DataFrame (columns=fixed_vars) # empty frame\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return tibble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "be61ef9e21933db811aa6d3f8f230999",
     "grade": true,
     "grade_id": "cast_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "table2 = pd.read_csv ('table2.csv')\n",
    "print ('=== table2 ===')\n",
    "display (table2)\n",
    "\n",
    "print ('\\n=== tibble2 = cast (table2, \"type\", \"count\") ===')\n",
    "tibble2 = cast (table2, 'type', 'count')\n",
    "display (tibble2)\n",
    "\n",
    "assert tibbles_are_equivalent (table1, tibble2)\n",
    "print ('\\n(Passed.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating variables\n",
    "\n",
    "Recall Table 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table3 = pd.read_csv ('table3.csv')\n",
    "display (table3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table has a different problem, which is that the `rate` variable actually combines the `cases` and `population` data. This example is an instance in which we need to _separate_ a column into two variables.\n",
    "\n",
    "**Exercise 5** (5 points). Write a function that takes a data frame (`df`) and separates an existing column (`key`) into new variables (given by the list of new variable names, `into`).\n",
    "\n",
    "How will the separation happen? The caller should provide a function, `splitter (x)`, that given a value returns a _list_ containing the components. Observe that the partial solution below defines a default splitter, which uses the regular expression, `(\\d+\\.?\\d+)`, to find all integer or floating-point values in a string input `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "bb30143689192a8e06fdb94dc6569e32",
     "grade": false,
     "grade_id": "sep",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def default_splitter (text):\n",
    "    \"\"\"Searches the given spring for all integer and floating-point\n",
    "    values, returning them as a list _of strings_.\n",
    "    \n",
    "    E.g., the call\n",
    "    \n",
    "      default_splitter ('Given me $10.52 in exchange for 91 kitten stickers.')\n",
    "      \n",
    "    will return ['10.52', '91'].\n",
    "    \"\"\"\n",
    "    fields = re.findall ('(\\d+\\.?\\d+)', text)\n",
    "    return fields\n",
    "\n",
    "def separate (df, key, into, splitter=default_splitter):\n",
    "    \"\"\"Given a data frame, separates one of its columns, the key,\n",
    "    into new variables.\n",
    "    \"\"\"\n",
    "    assert type (df) is pd.DataFrame\n",
    "    assert key in df.columns\n",
    "    \n",
    "    # Hint: http://stackoverflow.com/questions/16236684/apply-pandas-function-to-column-to-create-multiple-new-columns\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c60cc7e536938657b98ef52dd51d0439",
     "grade": true,
     "grade_id": "sep_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"=== Recall: table3 ===\")\n",
    "display (table3)\n",
    "\n",
    "tibble3 = separate (table3, key='rate', into=['cases', 'population'])\n",
    "print (\"\\n=== tibble3 = separate (table3, ...) ===\")\n",
    "display (tibble3)\n",
    "\n",
    "assert 'cases' in tibble3.columns\n",
    "assert 'population' in tibble3.columns\n",
    "assert 'rate' not in tibble3.columns\n",
    "\n",
    "tibble3['cases'] = tibble3['cases'].apply (int)\n",
    "tibble3['population'] = tibble3['population'].apply (int)\n",
    "\n",
    "assert tibbles_are_equivalent (tibble3, table1)\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (5 points). Implement the inverse of separate, which is `unite()`. This function should take a data frame (`df`), the set of columns to combine (`cols`), the name of the new column (`new_var`), and a function that takes the subset of `cols` variables from a single observation and returns a new value for that observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4b689216c496ca64e0f7b0d668eb4b85",
     "grade": false,
     "grade_id": "unite",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def str_join_elements (x, sep=\"\"):\n",
    "    assert type (sep) is str\n",
    "    return sep.join ([str (xi) for xi in x])\n",
    "\n",
    "def unite (df, cols, new_var, combine=str_join_elements):\n",
    "    # Hint: http://stackoverflow.com/questions/13331698/how-to-apply-a-function-to-two-columns-of-pandas-dataframe\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5dff5267767b49ac933967332854a779",
     "grade": true,
     "grade_id": "unite_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "table3_again = unite (tibble3, ['cases', 'population'], 'rate',\n",
    "                      combine=lambda x: str_join_elements (x, \"/\"))\n",
    "display (table3_again)\n",
    "assert tibbles_are_equivalent (table3, table3_again)\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Let's use primitives to tidy up the original WHO TB data set. First here is the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "who_raw = pd.read_csv ('who.csv')\n",
    "\n",
    "print (\"=== WHO TB data set: {} rows x {} columns ===\".format (who_raw.shape[0],\n",
    "                                                               who_raw.shape[1]))\n",
    "print (\"Column names:\", who_raw.columns)\n",
    "\n",
    "print (\"\\n=== A few randomly selected rows ===\")\n",
    "import random\n",
    "row_sample = sorted (random.sample (range (len (who_raw)), 5))\n",
    "display (who_raw.iloc[row_sample])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set has 7,240 rows and 60 columns. Here is how to decode the columns.\n",
    "- Columns `'country'`, `'iso2'`, and `'iso3'` are different ways to designate the country and redundant, meaning you only really need to keep one of them.\n",
    "- Column `'year'` is the year of the report and is a natural variable.\n",
    "- Among columns `'new_sp_m014'` through `'newrel_f65'`, the `'new...'` prefix indicates that the column's values count new cases of TB. In this particular data set, all the data are for new cases.\n",
    "- The short codes, `rel`, `ep`, `sn`, and `sp` describe the type of TB case. They stand for relapse, extrapulmonary, pulmonary not detectable by a pulmonary smear test (\"smear negative\"), and pulmonary detectable by such a test (\"smear positive\"), respectively.\n",
    "- The codes `'m'` and `'f'` indicate the gender (male and female, respectively).\n",
    "- The trailing numeric code indicates the age group: `014` is 0-14 years of age, `1524` for 15-24 years, `2534` for 25-34 years, etc., and `65` stands for 65 years or older.\n",
    "\n",
    "In other words, it looks like you are likely to want to treat all the columns as values of multiple variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** (3 points). As a first step, start with `who_raw` and create a new data frame, `who2`, with the following properties:\n",
    "\n",
    "- All the `'new...'` columns of `who_raw` become values of a _single_ variable, `case_type`. Store the counts associated with each `case_type` value as a new variable called `'count'`.\n",
    "- Remove the `iso2` and `iso3` columns, since they are redundant with `country` (which you should keep!).\n",
    "- Keep the `year` column as a variable.\n",
    "- Remove all not-a-number (`NaN`) counts. _Hint_: You can test for a `NaN` using Python's [`math.isnan()`](https://docs.python.org/3/library/math.html).\n",
    "- Convert the counts to integers. (Because of the presence of NaNs, the counts will be otherwise be treated as floating-point values, which is undesirable since you do not expect to see non-integer counts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "760ec65f80b3c4f94f4a9ac28ed080aa",
     "grade": false,
     "grade_id": "who2",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ade9b41db43f1be2a1211e939360e96d",
     "grade": true,
     "grade_id": "who2_test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"=== First few rows of your solution ===\")\n",
    "display (who2.head ())\n",
    "\n",
    "print (\"=== First few rows of the instructor's solution ===\")\n",
    "who2_soln = pd.read_csv ('who2_soln.csv')\n",
    "display (who2_soln.head ())\n",
    "\n",
    "# Check it\n",
    "assert tibbles_are_equivalent (who2, who2_soln)\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** (5 points). Starting from your `who2` data frame, create a new tibble, `who3`, for which each `'key'` value is split into three new variables:\n",
    "\n",
    "- `'type'`, to hold the TB type, having possible values of `rel`, `ep`, `sn`, and `sp`;\n",
    "- `'gender'`, to hold the gender as a string having possible values of `female` and `male`; and\n",
    "- `'age_group'`, to hold the age group as a string having possible values of `0-14`, `25-34`, `35-44`, `45-54`, `55-64`, and `65+`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "216b6d11cb39fdcf4c3a9bffa870ef25",
     "grade": false,
     "grade_id": "who3",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "219ae37bf444144aa605c7dfbdfce9cc",
     "grade": true,
     "grade_id": "who3_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"=== First few rows of your solution ===\")\n",
    "display (who3.head ())\n",
    "\n",
    "who3_soln = pd.read_csv ('who3_soln.csv')\n",
    "print (\"\\n=== First few rows of the instructor's solution ===\")\n",
    "display (who3_soln.head ())\n",
    "\n",
    "assert tibbles_are_equivalent (who3, who3_soln)\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
