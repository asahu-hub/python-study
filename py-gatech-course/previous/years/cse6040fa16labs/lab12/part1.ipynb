{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "# Important note!\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR_ID = \"\" # Please enter your GT login, e.g., \"rvuduc3\" or \"gtg911x\"\n",
    "COLLABORATORS = [] # list of strings of your collaborators' IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b11295002cc2b9549d6a2b01721b6701",
     "grade": true,
     "grade_id": "who__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_CHECK_ID = re.compile (r'''[a-zA-Z]+\\d+|[gG][tT][gG]\\d+[a-zA-Z]''')\n",
    "assert RE_CHECK_ID.match (YOUR_ID) is not None\n",
    "\n",
    "collab_check = [RE_CHECK_ID.match (i) is not None for i in COLLABORATORS]\n",
    "assert all (collab_check)\n",
    "\n",
    "del collab_check\n",
    "del RE_CHECK_ID\n",
    "del re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter / IPython version check.** The following code cell verifies that you are using the correct version of Jupyter/IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering via $k$-means\n",
    "\n",
    "Last week, we studied the classification problem using the logistic regression algorithm. Since we had labels for each data point, we may regard the problem as one of _supervised learning_. However, in many applications, the data have no labels but we wish to discover possible labels (or other hidden patterns or structures). This problem is one of _unsupervised learning_. How can we approach such problems?\n",
    "\n",
    "**Clustering** is one class of unsupervised learning methods. In this lab, we'll consider the following form of the clustering task. Suppose you are given\n",
    "\n",
    "- a set of observations, $X \\equiv \\{\\hat{x}_i \\,|\\, 0 \\leq i < n\\}$, and\n",
    "- a target number of _clusters_, $k$.\n",
    "\n",
    "Your goal is to partition the points into $k$ subsets, $C_0,\\dots, C_{k-1} \\subset X$, which are\n",
    "\n",
    "- disjoint, i.e., $i \\neq j \\implies C_i \\cap C_j = \\emptyset$);\n",
    "- but also complete, i.e., $C_0 \\cup C_1 \\cup \\cdots \\cup C_{k-1} = X$.\n",
    "\n",
    "Intuitively, each cluster should reflect some \"sensible\" grouping. Thus, we need to specify what constitutes such a grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The $k$-means clustering criterion\n",
    "\n",
    "Here is one way to measure the quality of a set of clusters. For each cluster $C$, consider its center $\\mu$ and measure the distance $\\|x-\\mu\\|$ of each observation $x \\in C$ to the center. Add these up for all points in the cluster; call this sum is the _within-cluster sum-of-squares (WCSS)_. Then, set as our goal to choose clusters that minimize the total WCSS over _all_ clusters.\n",
    "\n",
    "More formally, given a clustering $C = \\{C_0, C_1, \\ldots, C_{k-1}\\}$, let\n",
    "\n",
    "$$\n",
    "  \\mathrm{WCSS}(C) \\equiv \\sum_{i=0}^{k-1} \\sum_{x\\in C_i} \\|x - \\mu_i\\|^2,\n",
    "$$\n",
    "\n",
    "where $\\mu_i$ is the center of $C_i$. This center may be computed simply as the mean of all poitns in $C_i$, i.e.,\n",
    "\n",
    "$$\n",
    "  \\mu_i \\equiv \\dfrac{1}{|C_i|} \\sum_{x \\in C_i} x.\n",
    "$$\n",
    "\n",
    "Then, our objective is to find the clustering such that\n",
    "\n",
    "$$\n",
    "  \\arg\\min_C \\mathrm{WCSS}(C).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The standard $k$-means algorithm (Lloyd's algorithm)\n",
    "\n",
    "Finding the global optimum is [NP-hard](https://en.wikipedia.org/wiki/NP-hardness), which is computer science mumbo jumbo for \"we don't know whether there is an algorithm to calculate the exact answer in fewer steps than exponential in the size of the input.\" Nevertheless, there is an iterative method, Lloydâ€™s algorithm, that can quickly converge to a _local_ (as opposed to _global_) minimum. The procedure alternates between two operations:\n",
    "\n",
    "**Step 1: Assignment.** Given a fixed set of $k$ centers, assign each point to the nearest center:\n",
    "\n",
    "$$\n",
    "  C_i = \\{\\hat{x}: \\| \\hat{x} - \\mu_i \\| \\le \\| \\hat{x} - \\mu_j \\|, 1 \\le j \\le k \\}.\n",
    "$$\n",
    "\n",
    "**Step 2: Update.** Recompute the $k$ centers (\"centroids\") by averaging all the data points belonging to each cluster, i.e., taking their mean:\n",
    "\n",
    "$$\n",
    "  \\mu_i = \\dfrac{1}{|C_i|} \\sum_{\\hat{x} \\in C_i} \\hat{x}\n",
    "$$\n",
    "\n",
    "![Illustration of $k$-means](http://stanford.edu/~cpiech/cs221/img/kmeansViz.png)\n",
    "\n",
    "> Figure stolen without permission from: http://stanford.edu/~cpiech/cs221/img/kmeansViz.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code that follows, it will be convenient to use our usual \"data matrix\" convention, that is, each row of a data matrix $X$ is one of $m$ observations and each column (coordinate) is one of $d$ predictors. However, we will _not_ need a dummy column of ones since we are not fitting a function per se.\n",
    "\n",
    "$$\n",
    "  X\n",
    "  \\equiv \\left(\\begin{array}{c} \\hat{x}_0^T \\\\ \\vdots \\\\ \\hat{x}_{m}^T \\end{array}\\right)\n",
    "  = \\left(\\begin{array}{ccc} x_0 & \\cdots & x_{d-1} \\end{array}\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the same dataset from the last logistic regression lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv ('logreg_points_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper functions from Lab 10:\n",
    "def make_scatter_plot (df, x=\"x_1\", y=\"x_2\", hue=\"label\",\n",
    "                       palette={0: \"red\", 1: \"olive\"},\n",
    "                       size=5,\n",
    "                       centers=None):\n",
    "    sns.lmplot (x=x, y=y, hue=hue, data=df, palette=palette,\n",
    "                fit_reg=False)\n",
    "    if centers is not None:\n",
    "        plt.scatter (centers[:,0], centers[:,1],\n",
    "                     marker=u'*', s=500,\n",
    "                     c=[palette[0], palette[1]])\n",
    "    \n",
    "def mark_matches (a, b, exact=False):\n",
    "    \"\"\"\n",
    "    Given two Numpy arrays of {0, 1} labels, returns a new boolean\n",
    "    array indicating at which locations the input arrays have the\n",
    "    same label (i.e., the corresponding entry is True).\n",
    "    \n",
    "    This function can consider \"inexact\" matches. That is, if `exact`\n",
    "    is False, then the function will assume the {0, 1} labels may be\n",
    "    regarded as the same up to a swapping of the labels. This feature\n",
    "    allows\n",
    "    \n",
    "      a == [0, 0, 1, 1, 0, 1, 1]\n",
    "      b == [1, 1, 0, 0, 1, 0, 0]\n",
    "      \n",
    "    to be regarded as equal. (That is, use `exact=False` when you\n",
    "    only care about \"relative\" labeling.)\n",
    "    \"\"\"\n",
    "    assert a.shape == b.shape\n",
    "    a_int = a.astype (dtype=int)\n",
    "    b_int = b.astype (dtype=int)\n",
    "    all_axes = tuple (range (len (a.shape)))\n",
    "    assert ((a_int == 0) | (a_int == 1)).all ()\n",
    "    assert ((b_int == 0) | (b_int == 1)).all ()\n",
    "    \n",
    "    exact_matches = (a_int == b_int)\n",
    "    if exact:\n",
    "        return exact_matches\n",
    "\n",
    "    assert exact == False\n",
    "    num_exact_matches = np.sum (exact_matches)\n",
    "    if (2*num_exact_matches) >= np.prod (a.shape):\n",
    "        return exact_matches\n",
    "    return exact_matches == False # Invert\n",
    "    \n",
    "def count_matches (a, b, exact=False):\n",
    "    \"\"\"\n",
    "    Given two sets of {0, 1} labels, returns the number of mismatches.\n",
    "    \n",
    "    This function can consider \"inexact\" matches. That is, if `exact`\n",
    "    is False, then the function will assume the {0, 1} labels may be\n",
    "    regarded as similar up to a swapping of the labels. This feature\n",
    "    allows\n",
    "    \n",
    "      a == [0, 0, 1, 1, 0, 1, 1]\n",
    "      b == [1, 1, 0, 0, 1, 0, 0]\n",
    "      \n",
    "    to be regarded as equal. (That is, use `exact=False` when you\n",
    "    only care about \"relative\" labeling.)\n",
    "    \"\"\"\n",
    "    matches = mark_matches (a, b, exact=exact)\n",
    "    return np.sum (matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_scatter_plot (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = df.as_matrix (['x_1', 'x_2'])\n",
    "labels = df['label'].as_matrix ()\n",
    "n, d = points.shape\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the labels should _not_ be used in the $k$-means algorithm. We use them here only as ground truth for later verification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to start? Initializing the $k$ centers\n",
    "\n",
    "To start the algorithm, you need an initial guess. Let's randomly choose $k$ observations from the data.\n",
    "\n",
    "**Exercise 1** (2 points). Complete the following function, which should randomly select $k$ of the given observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "81ed24b96251b029f1c484c4fea4eee2",
     "grade": false,
     "grade_id": "init_centers",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def init_centers (X, k):\n",
    "    \"\"\"\n",
    "    Randomly samples k observations from X as centers.\n",
    "    Returns these centers as a (k x d) numpy array.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "46325a4bf873312bee8c227f2671645a",
     "grade": true,
     "grade_id": "init_centers_test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "centers_initial = init_centers (points, k)\n",
    "print (\"Initial centers:\\n\", centers_initial)\n",
    "\n",
    "assert centers_initial.shape == (k, d)\n",
    "assert (sum (centers_initial[0, :] == points) == [1, 1]).all ()\n",
    "assert (sum (centers_initial[1, :] == points) == [1, 1]).all ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the distances\n",
    "\n",
    "**Exercise 2** (3 points). Implement a function that computes a distance matrix, $S = (s_{ij})$ such that $s_{ij} = d_{ij}^2$ is the _squared_ distance from point $\\hat{x}_i$ to center $\\mu_j$. It should return a Numpy matrix `S[:m, :k]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bcbbab0d3cde13d5ae1c3150c87d850c",
     "grade": false,
     "grade_id": "compute_d2",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_d2 (X, centers):\n",
    "    m = len (X)\n",
    "    k = len (centers)\n",
    "    \n",
    "    S = np.empty((m, k))\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "421d622ba286519664371f535207573f",
     "grade": true,
     "grade_id": "centers_initial_testing",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "centers_initial_testing = np.load (\"centers_initial_testing.npy\")\n",
    "compute_d2_soln = np.load (\"compute_d2_soln.npy\")\n",
    "\n",
    "S = compute_d2 (points, centers_initial_testing)\n",
    "assert (np.linalg.norm (S - compute_d2_soln, axis=1) <= (10.0 * np.finfo(float).eps)).all ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** (2 points). Write a function that uses the (squared) distance matrix to assign a \"cluster label\" to each point.\n",
    "\n",
    "That is, consider the $m \\times k$ squared distance matrix $S$. For each point $i$, if $s_{i,j}$ is the minimum squared distance for point $i$, then the index $j$ is $i$'s cluster label. In other words, your function should return a (column) vector $y$ of length $m$ such that\n",
    "\n",
    "$$\n",
    "  y_i = \\underset{j \\in \\{0, \\ldots, k-1\\}}{\\operatorname{argmin}} s_{ij}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9242615a739874c44b28e56e1a0f4dac",
     "grade": false,
     "grade_id": "assign_cluster_labels",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def assign_cluster_labels (S):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5aec8326d9351b2135f9c3ceff0009d2",
     "grade": true,
     "grade_id": "assign_cluster_labels_test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "S_test1 = [[0.3, 0.2],\n",
    "           [0.1, 0.5],\n",
    "           [0.4, 0.2]]\n",
    "y_test1 = assign_cluster_labels (S_test1)\n",
    "assert (y_test1 == np.array ([1, 0, 1])).all ()\n",
    "\n",
    "S_test2 = np.load (\"assign_cluster_labels_S.npy\")\n",
    "y_test2_soln = np.load (\"assign_cluster_labels_soln.npy\")\n",
    "y_test2 = assign_cluster_labels (S_test2)\n",
    "assert (y_test2 == y_test2_soln).all ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (3 points). Given a clustering (i.e., a set of points and assignment of labels), compute the center of each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "dd112eff444b0f34a1254cf2f2f0c64e",
     "grade": false,
     "grade_id": "update_centers",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def update_centers (X, y):\n",
    "    # X[:m, :d] == m points, each of dimension d\n",
    "    # y[:m] == set of cluster labels\n",
    "    m, d = X.shape\n",
    "    k = max (y) + 1\n",
    "    assert m == len (y)\n",
    "    assert (min (y) >= 0)\n",
    "    \n",
    "    centers = np.empty ((k, d))\n",
    "    for j in range (k):\n",
    "        # Compute the new center of cluster j,\n",
    "        # i.e., centers[j, :d].\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "aa59adac94237daedbbdbff0521f0471",
     "grade": true,
     "grade_id": "update_centers_test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_test3 = np.load (\"y_test3.npy\")\n",
    "centers_test3_soln = np.load (\"centers_test3_soln.npy\")\n",
    "centers_test3 = update_centers (points, y_test3)\n",
    "\n",
    "delta_test3 = np.abs (centers_test3 - centers_test3_soln)\n",
    "assert (delta_test3 <= 2.0*len (centers_test3_soln)*np.finfo (float).eps).all ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** (3 points). Given the squared distances, return the within-cluster sum of squares.\n",
    "\n",
    "> _Hint_: See [numpy.amin](https://docs.scipy.org/doc/numpy/reference/generated/numpy.amin.html#numpy.amin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0640817a2050b864822af694de7caeb5",
     "grade": false,
     "grade_id": "wcss",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def WCSS (S):\n",
    "    # For example, S = [[0.3, 0.2],\n",
    "    #                   [0.1, 0.5],\n",
    "    #                   [0.4, 0.2]]\n",
    "    # should return 0.2 + 0.1 + 0.2 = 0.5\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d284da43eae0b88aa531bba106b50a8d",
     "grade": true,
     "grade_id": "wcss_test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "S_test1 = [[0.3, 0.2],\n",
    "           [0.1, 0.5],\n",
    "           [0.4, 0.2]]\n",
    "wcss_test1 = WCSS (S_test1)\n",
    "print (wcss_test1)\n",
    "assert np.abs (wcss_test1 - 0.5) <= 3.0*np.finfo (float).eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, here is a function to check whether the centers have \"moved,\" given two instances of the center values. It accounts for the fact that the order of centers may have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def has_converged (old_centers, centers):\n",
    "    return set ([tuple(x) for x in old_centers]) == set ([tuple(x) for x in centers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (4 points). Put all of the preceding building blocks together by implementing the standard $k$-means algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "423111a8da72858defe99831f07ef6df",
     "grade": true,
     "grade_id": "kmeans",
     "locked": false,
     "points": 5,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def kmeans (X, k,\n",
    "            starting_centers=None,\n",
    "            max_steps=np.inf):\n",
    "    if not starting_centers:\n",
    "        centers = init_centers (X, k)\n",
    "    else:\n",
    "        centers = starting_centers\n",
    "        \n",
    "    converged = False\n",
    "    labels = np.zeros (len (X))\n",
    "    i = 1\n",
    "    while (not converged) and (i <= max_steps):\n",
    "        old_centers = centers\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        print (\"iteration\", i, \"WCSS = \", WCSS (S))\n",
    "        i += 1\n",
    "    return labels\n",
    "\n",
    "clustering = kmeans (points, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['clustering'] = clustering\n",
    "centers = update_centers (points, clustering)\n",
    "make_scatter_plot (df, hue='clustering', centers=centers)\n",
    "\n",
    "n_matches = count_matches (df['label'], df['clustering'])\n",
    "print (n_matches,\n",
    "       \"matches out of\",\n",
    "       len (df), \"possible\",\n",
    "       \"(~ {:.1f}%)\".format (100.0 * n_matches / len (df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Built-in $k$-means\n",
    "\n",
    "The preceding exercises walked you through how to implement $k$-means, but as you might have imagined, there are existing implementations as well! The following shows you how to use Scipy's implementation, which should yield similar results. If you are asked to use $k$-means in a future lab (or exam!), you can use this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster import vq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# `distortion` below is the similar to WCSS.\n",
    "# It is called distortion in the Scipy documentation\n",
    "# since clustering can be used in compression.\n",
    "centers_vq, distortion_vq = vq.kmeans (points, k)\n",
    "\n",
    "# vq return the clustering (assignment of group for each point)\n",
    "# based on the centers obtained by the kmeans function.\n",
    "# _ here means ignore the second return value\n",
    "clustering_vq, _ = vq.vq (points, centers_vq)\n",
    "\n",
    "print (\"Centers:\\n\", centers_vq)\n",
    "print (\"\\nCompare with your method:\\n\", centers, \"\\n\")\n",
    "print (\"Distortion (WCSS):\", distortion_vq)\n",
    "\n",
    "df['clustering_vq'] = clustering_vq\n",
    "make_scatter_plot (df, hue='clustering_vq', centers=centers_vq)\n",
    "\n",
    "n_matches_vq = count_matches (df['label'], df['clustering_vq'])\n",
    "print (n_matches_vq,\n",
    "       \"matches out of\",\n",
    "       len (df), \"possible\",\n",
    "       \"(~ {:.1f}%)\".format (100.0 * n_matches_vq / len (df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
