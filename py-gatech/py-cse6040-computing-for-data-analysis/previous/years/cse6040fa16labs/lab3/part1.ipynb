{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "# Important note!\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR_ID = \"\" # Please enter your GT login, e.g., \"rvuduc3\" or \"gtg911x\"\n",
    "COLLABORATORS = [] # list of strings of your collaborators' IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b11295002cc2b9549d6a2b01721b6701",
     "grade": true,
     "grade_id": "who__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_CHECK_ID = re.compile (r'''[a-zA-Z]+\\d+|[gG][tT][gG]\\d+[a-zA-Z]''')\n",
    "assert RE_CHECK_ID.match (YOUR_ID) is not None\n",
    "\n",
    "collab_check = [RE_CHECK_ID.match (i) is not None for i in COLLABORATORS]\n",
    "assert all (collab_check)\n",
    "\n",
    "del collab_check\n",
    "del RE_CHECK_ID\n",
    "del re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter / IPython version check.** The following code cell verifies that you are using the correct version of Jupyter/IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mining the web, part 1 (13 points)\n",
    "\n",
    "Perhaps the richest source of openly available data today is [the Web](http://www.computerhistory.org/revolution/networking/19/314)! In this lab, you'll explore some of the basic programming tools you need to scrape web data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: The Requests module\n",
    "\n",
    "In Lab 1, you used Python's [Requests module](http://requests.readthedocs.io/en/latest/user/quickstart/) to download a file.\n",
    "\n",
    "For instance, here is a code fragment to download the GT home page and print the first 250 characters. You might also want to [view the source](http://www.computerhope.com/issues/ch000746.htm) of Georgia Tech's home page to get a nicely formatted view, and compare its output to what you see above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get ('http://www.gatech.edu/')\n",
    "webpage = response.text  # or response.content for raw bytes\n",
    "\n",
    "print (webpage[0:250]) # Prints the first hundred characters only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** (3 points). Given the contents of the GT home page as above, write a function that returns a list of links (URLs) of the \"top stories\" on the page.\n",
    "\n",
    "For instance, on Friday, September 9, 2016, here was the front page:\n",
    "\n",
    "![www.gatech.edu as of Fri Sep 9, 2016](./www.gatech.edu--2016-09-09--annotated-medium.png)\n",
    "\n",
    "The top stories cycle through in the large image placeholder shown above. We want your function to return the list of URLs behind each of the \"Full Story\" links, highlighted in red. If no URLs can be found, the function should return an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "4207f0dcd2ef4e815d7d59ae3e22862c",
     "grade": false,
     "grade_id": "get_top_stories",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import re # Maybe you want to use a regular expression?\n",
    "\n",
    "def get_gt_top_stories (webpage_text):\n",
    "    \"\"\"Given the HTML text for the GT front page, returns a list\n",
    "    of the URLs of the top stories or an empty list if none are\n",
    "    found.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_stories = get_gt_top_stories (webpage)\n",
    "print (\"Links to GT's top stories:\", top_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1bcd69c046f648fa10550da2e26574bd",
     "grade": true,
     "grade_id": "get_top_story__test1",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert \"http://www.news.gatech.edu/features/beltline-impact\" in top_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ece3aa8ec9edde61d87d8f729a4aaa82",
     "grade": true,
     "grade_id": "get_top_story__test2",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len (get_gt_top_stories ('')) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more complex example\n",
    "\n",
    "Go to [Yelp!](http://www.yelp.com) and look up `ramen` in `Atlanta, GA`. Take note of the URL:\n",
    "\n",
    "![Yelp! search for ramen in ATL](./yelp-search-example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This URL encodes what is known as an _HTTP \"get\"_ method (or request). It basically means a URL with two parts: a _command_ followed by one or more _arguments_. In this case, the command is everything up to and including the word `search`; the arguments are the rest, where individual arguments are separated by the `&` or `#`.\n",
    "\n",
    "> \"HTTP\" stands for \"HyperText Transport Protocol,\" which is a standardized set of communication protocols that allow _web clients_, like your web browser or your Python program, to communicate with _web servers_.\n",
    "\n",
    "In this next example, let's see how to build a \"get request\" with the `requests` module. It's pretty easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_command = 'http://yelp.com/search'\n",
    "url_args = {'find_desc': \"ramen\",\n",
    "            'find_loc': \"atlanta, ga\"}\n",
    "response = requests.get (url_command, params=url_args)\n",
    "\n",
    "print (\"==> Downloading from: '%s'\" % response.url) # confirm URL\n",
    "print (\"\\n==> Excerpt from this URL:\\n\\n%s\\n\" % response.text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** (6 points). Given a search topic, location, and a rank $k$, return the name of the $k$-th item of a Yelp! search. If there is no $k$-th item, return `None`.\n",
    "\n",
    "> The demo query above only gives you a website with the top 10 items, meaning you could only use it for $k \\leq 10$. Figure out how to modify it to solve the problem when $k > 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "1d3eebbb35d7e89e7f0b584ace5eb590",
     "grade": false,
     "grade_id": "yelp_find_item",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_yelp_item (topic, location, k):\n",
    "    \"\"\"Returns the k-th suggested item from Yelp! in Atlanta for the given topic.\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6d0832389ce9218cb442934f4b13fb80",
     "grade": true,
     "grade_id": "yelp_atl__test1",
     "locked": true,
     "points": 0.5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert find_yelp_item ('fried chicken', 'Atlanta, GA', -1) is None # Tests an invalid value for 'k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Search queries on Yelp! don't always return the same answers, since the site is always changing! Also, your results might not match a query you do via your web browser (_why not?_). As such, you should manually check your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ff2d23bcdd964698122037cb2fe7888b",
     "grade": true,
     "grade_id": "yelp_atl__test2",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "item = find_yelp_item ('fried chicken', 'Atlanta, GA', 1)\n",
    "print (item)\n",
    "\n",
    "# Correct answer as of September 10, 2016:\n",
    "#assert item == 'Gus’s World Famous <span class=\"highlighted\">Fried</span> <span class=\"highlighted\">Chicken</span>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "718e0bb43efcb264a9c695d9646f947d",
     "grade": true,
     "grade_id": "yelp_atl__test3",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "item = find_yelp_item ('fried chicken', 'Atlanta, GA', 5)\n",
    "print (item)\n",
    "\n",
    "# Correct answer as of September 10, 2016:\n",
    "#assert item == 'Mary Mac’s Tea Room'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "cb74e86381fd81b6d420042f9c5aec81",
     "grade": true,
     "grade_id": "yelp_atl__test4",
     "locked": true,
     "points": 1.5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "item = find_yelp_item ('fried chicken', 'Atlanta, GA', 17)\n",
    "print (item)\n",
    "\n",
    "# Correct answer as of September 10, 2016:\n",
    "#assert item == 'Fox Bros. Bar-B-Q'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Parsing HTML: Beautiful Soup\n",
    "\n",
    "HTML files are, of course, highly structured files. As such, you can imagine there are much more systematic methods and tools to process them. One such package is [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/). The following is a quick tutorial on how to use it.\n",
    "\n",
    "Any HTML document may be modeled as a tree:\n",
    "\n",
    "![HTML as a tree](./html-slide.png)\n",
    "\n",
    "> For whatever reason, [computer scientists usually view trees upside down](https://www.quora.com/Why-are-trees-in-computer-science-generally-drawn-upside-down-from-how-trees-are-in-real-life), with the \"root\" at the top and the \"leaves\" at the bottom.\n",
    "\n",
    "The Beautiful Soup package gives you a data structure for traversing this tree. For instance, consider an HTML file with the contents below, shown both as code and pictorially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "some_page = \"\"\"\n",
    "<html>\n",
    "  <body>\n",
    "    <p>First paragraph.</p>\n",
    "    <p>Second paragraph, which links to the <a href=\"http://www.gatech.edu\">Georgia Tech website</a>.</p>\n",
    "    <p>Third paragraph.</p>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Two visual representations of `some_page`](./html-viz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** (1 point). Besides HTML files, what else have we seen in this class that could be represented by a tree? Briefly and roughly explain what and how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "70d56b8ad719afcee203a569328546d0",
     "grade": true,
     "grade_id": "other_trees",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you might use Beautiful Soup to inspect the structure of `some_page`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup (some_page, \"lxml\")\n",
    "print (type (soup.html.body.contents), '::', soup.html.body.contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (1 point). Write some code to display the contents of `soup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "54ecc3f8b6c1489e332d1cb080c6b012",
     "grade": true,
     "grade_id": "soup_contents",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** (1 point). Write a statement that navigates to the tag representing the GT website link. Store this resulting tag object in a variable called `link`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "187e99421c1176a0911f56cf06a02611",
     "grade": false,
     "grade_id": "get_tag",
     "locked": false,
     "points": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Observe how the following test code checks your result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a6f8c8edbd503583c6eee5fdf79ab436",
     "grade": true,
     "grade_id": "get_tag_test1",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (link)\n",
    "\n",
    "import bs4\n",
    "assert type (link) is bs4.element.Tag\n",
    "assert link.name == 'a'\n",
    "assert link['href'] == 'http://www.gatech.edu'\n",
    "assert link.contents == ['Georgia Tech website']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other navigation tools\n",
    "\n",
    "This lab includes a static copy of the Yelp! results for a search of \"universities\" in ATL. Here is some code that opens that file and prints the number 1 result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uni_html_text = open ('yelp_atl_unies.html', 'r').read ()\n",
    "uni_soup = BeautifulSoup (uni_html_text, \"lxml\")\n",
    "\n",
    "print (\"The number 1 ATL university according to Yelp!:\")\n",
    "\n",
    "uni_1 = uni_soup.html.body \\\n",
    "    .contents[7] \\\n",
    "    .contents[9] \\\n",
    "    .contents[3] \\\n",
    "    .contents[1] \\\n",
    "    .contents[3] \\\n",
    "    .contents[1] \\\n",
    "    .contents[1] \\\n",
    "    .contents[7] \\\n",
    "    .contents[3] \\\n",
    "    .contents[5] \\\n",
    "    .contents[1] \\\n",
    "    .contents[1] \\\n",
    "    .contents[1] \\\n",
    "    .contents[1] \\\n",
    "    .contents[3] \\\n",
    "    .contents[1] \\\n",
    "    .contents[1] \\\n",
    "    .contents[1] \\\n",
    "    .contents[0] \\\n",
    "    .contents[0]\n",
    "    \n",
    "print (uni_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope it is self-evident that the above method to navigate to a particular tag or element is not terribly productive or robust.\n",
    "\n",
    "Here is an alternative. Inspect the raw HTML and observe that every non-ad search result appears in a tag of the form,\n",
    "\n",
    "```html\n",
    "<span class=\"indexed-biz-name\">1.         <a class=\"biz-name js-analytics-click\" data-analytics-label=\"biz-name\" href=\"/biz/georgia-institute-of-technology-atlanta-2\" data-hovercard-id=\"gBX8UvhOwtdD5tGJeU-hxg\" ><span >Georgia Institute of Technology</span></a>\n",
    "</span>\n",
    "```\n",
    "\n",
    "Beautiful Soup gives us a way to search for specific tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexed_unies = uni_soup.find_all (attrs={'class': 'indexed-biz-name'})\n",
    "print (indexed_unies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (4 points). Based on the above, write a function that, given a Yelp! search results page such as `uni_soup` above, returns the name of the number 1 indexed search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6c198d426ec6f8d51a405cceded667b9",
     "grade": false,
     "grade_id": "find_top",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_top_yelp_result (soup):\n",
    "    \"\"\"Given a Yelp! search result as a Beautiful Soup page,\n",
    "    returns the name of the number 1 indexed result.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d07fb1c8f89a9539b159ec2e781106a8",
     "grade": true,
     "grade_id": "find_top_test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (get_top_yelp_result (uni_soup))\n",
    "assert get_top_yelp_result (uni_soup) == 'Georgia Institute of Technology'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mini-tutorial only scratches the surface of what is possible with Beautiful Soup. As always, refer to the [package's documentation](https://www.crummy.com/software/BeautifulSoup/) for all the awesome deets!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
