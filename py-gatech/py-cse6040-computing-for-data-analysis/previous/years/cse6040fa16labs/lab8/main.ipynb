{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "solution": false
    }
   },
   "source": [
    "# Important note!\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "YOUR_ID = \"\" # Please enter your GT login, e.g., \"rvuduc3\" or \"gtg911x\"\n",
    "COLLABORATORS = [] # list of strings of your collaborators' IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b11295002cc2b9549d6a2b01721b6701",
     "grade": true,
     "grade_id": "who__test",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_CHECK_ID = re.compile (r'''[a-zA-Z]+\\d+|[gG][tT][gG]\\d+[a-zA-Z]''')\n",
    "assert RE_CHECK_ID.match (YOUR_ID) is not None\n",
    "\n",
    "collab_check = [RE_CHECK_ID.match (i) is not None for i in COLLABORATORS]\n",
    "assert all (collab_check)\n",
    "\n",
    "del collab_check\n",
    "del RE_CHECK_ID\n",
    "del re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter / IPython version check.** The following code cell verifies that you are using the correct version of Jupyter/IPython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "assert IPython.version_info[0] >= 3, \"Your version of IPython is too old, please update it.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PageRank [39 points]\n",
    "\n",
    "In this notebook, you'll implement the [PageRank algorithm](http://ilpubs.stanford.edu:8090/422/) summarized in class. You'll test it on a real dataset (circa 2005) that consists of [political blogs](http://networkdata.ics.uci.edu/data/polblogs/) and their links among one another.\n",
    "\n",
    "For today's notebook, you'll need to download the following additional materials:\n",
    "* A SQLite version of the political blogs dataset: http://cse6040.gatech.edu/datasets/poliblogs.db (~ 611 KiB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some modules you'll need\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.io as spio\n",
    "import cse6040utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Explore the Dataset\n",
    "\n",
    "Let's start by looking at the dataset, to get a feel for what it contains.\n",
    "\n",
    "In this part, try to rely primarily on SQL queries to accomplish each task. This scenario is appropriate if the database is so large that you cannot expect to load it all into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incidentally, one of you asked recently how to get the schema for a SQLite database when using Python. Here is some code adapted from a few ideas floating around on the web. Let's use these to inspect the tables available in the political blogs dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3 as db\n",
    "import pandas as pd\n",
    "\n",
    "def get_table_names (conn):\n",
    "    assert type (conn) == db.Connection # Only works for sqlite3 DBs\n",
    "    query = \"select name from sqlite_master where type='table'\"\n",
    "    return pd.read_sql_query (query, conn)\n",
    "\n",
    "def print_schemas (conn, table_names=None, limit=0):\n",
    "    assert type (conn) == db.Connection # Only works for sqlite3 DBs\n",
    "    if table_names is None:\n",
    "        table_names = get_table_names (conn)\n",
    "    c = conn.cursor ()\n",
    "    query = \"pragma table_info ({table})\"\n",
    "    for name in table_names:\n",
    "        c.execute (query.format (table=name))\n",
    "        columns = c.fetchall ()\n",
    "        print (\"=== {table} ===\".format (table=name))\n",
    "        col_string = \"[{id}] {name} : {type}\"\n",
    "        for col in columns:\n",
    "            print (col_string.format (id=col[0],\n",
    "                                      name=col[1],\n",
    "                                      type=col[2]))\n",
    "        print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = db.connect ('poliblogs.db')\n",
    "\n",
    "for name in get_table_names (conn)['name']:\n",
    "    print_schemas (conn, [name])\n",
    "    query = '''select * from %s limit 5''' % name\n",
    "    display (pd.read_sql_query (query, conn))\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1.** (3 points). Write a snippet of code to verify that the vertex IDs are _dense_ in some interval $[1, n]$. That is, there is a minimum value of $1$, some maximum value $n$, and _no_ missing values between $1$ and $n$.\n",
    "\n",
    "Also store the number of vertices $n$ in a variable named `num_vertices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4a40490daef1adb7d273099a99e63ffb",
     "grade": false,
     "grade_id": "check_verts",
     "locked": false,
     "points": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "14ea202240d0c065cd344d0b49abe90b",
     "grade": true,
     "grade_id": "check_verts__test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert num_vertices == 1490"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "points": 3,
     "solution": false
    }
   },
   "source": [
    "**Exercise 2** (3 points). Make sure every edge has its end points in the vertex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5cf69aaa11e8e0f38d9ef91922a990bc",
     "grade": true,
     "grade_id": "check_edges",
     "locked": false,
     "points": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select min (Source), max (Source), min (Target), max (Target) from Edges\n",
    "'''\n",
    "pd.read_sql_query (query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** (2 points). Determine which vertices have no outgoing edges. Store the result in a Pandas `DataFrame` named `df_deadends` with a single column named `Id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bdca7cd278f395bf08c7c3ec29d9a561",
     "grade": false,
     "grade_id": "num_deadends",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "display (df_deadends.head ())\n",
    "display (df_deadends.tail ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a6172ec6188a579e8b368edb4befddef",
     "grade": true,
     "grade_id": "num_solo_vertices__test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"\\n==> %d vertices have no outgoing edges.\" % len (df_deadends))\n",
    "\n",
    "df_deadends_soln = pd.read_csv ('df_deadends_soln.csv')\n",
    "assert cse6040utils.tibbles_are_equivalent (df_deadends, df_deadends_soln)\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** (2 points). Determine which vertices that have no incoming edges. Store the result in a Pandas `DataFrame` called `df_nolove` having just a single column named `Id` to hold the corresponding vertex IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8f198d53a0a304708680eeca31f6f1a8",
     "grade": false,
     "grade_id": "df_nolove",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "display (df_nolove.head ())\n",
    "display (df_nolove.tail ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4fea97aba0d22580937899d345fd799e",
     "grade": true,
     "grade_id": "df_nolove__test",
     "locked": true,
     "points": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print (\"\\n==> %d vertices have no incoming edges.\" % len (df_nolove))\n",
    "\n",
    "df_nolove_soln = pd.read_csv ('df_nolove_soln.csv')\n",
    "assert cse6040utils.tibbles_are_equivalent (df_nolove, df_nolove_soln)\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** (3 points). Compute an [SQL view](https://www.sqlite.org/lang_createview.html) called `Outdegrees`, which contains the following columns:\n",
    "\n",
    "1. `Id`: vertex ID\n",
    "2. `Degree`: the out-degree of the corresponding vertex.\n",
    "\n",
    "To help you check your view, the test code selects from your view but adds a `Url` and `Leaning` fields, ordering the results in descending order of degree. It also prints first few and last few rows of this query, so you can inspect the URLs as a sanity check. (Perhaps it also provides a small bit of entertainment!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "921ad37cab643b6db3be608205ba4b18",
     "grade": false,
     "grade_id": "outdegrees",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Remove an existing view, if it exists:\n",
    "c = conn.cursor ()\n",
    "c.execute ('drop view if exists Outdegrees')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "87d3a0c04a1bcae717faf85ac98c78b3",
     "grade": true,
     "grade_id": "outdegrees__test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select Outdegrees.Id, Degree, Url, Leaning\n",
    "    from Outdegrees, Vertices\n",
    "    where Outdegrees.Id=Vertices.Id\n",
    "    order by -Degree\n",
    "'''\n",
    "df_outdegrees = pd.read_sql_query (query, conn)\n",
    "print (\"==> A few entries with large out-degrees:\")\n",
    "display (df_outdegrees.head (10))\n",
    "print (\"\\n==> A few entries with small out-degrees:\")\n",
    "display (df_outdegrees.tail ())\n",
    "\n",
    "df_outdegrees_soln = pd.read_csv ('outdegrees_soln.csv')\n",
    "assert cse6040utils.tibbles_are_equivalent (df_outdegrees, df_outdegrees_soln)\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** (3 points). Compute an [SQL view](https://www.sqlite.org/lang_createview.html) called `Indegrees`, which contains the following columns:\n",
    "\n",
    "1. `Id`: vertex ID\n",
    "2. `Degree`: the in-degree of this vertex.\n",
    "\n",
    "Your view should only include vertices with positive out-degree. (That is, if the in-degree is zero, you may leave it out of the resulting view.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "4f7339933425c49a3b4d3b7692dd9287",
     "grade": false,
     "grade_id": "indegrees",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Remove an existing view, if it exists:\n",
    "c = conn.cursor ()\n",
    "c.execute ('drop view if exists Indegrees')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "29e80b2073859bee07b4561b3eb5acb1",
     "grade": true,
     "grade_id": "indegrees__test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "  select Indegrees.Id, Degree, Url, Leaning\n",
    "    from Indegrees, Vertices\n",
    "    where Indegrees.Id=Vertices.Id\n",
    "    order by -Degree\n",
    "'''\n",
    "df_outdegrees = pd.read_sql_query (query, conn)\n",
    "print (\"==> A few entries with large in-degrees:\")\n",
    "display (df_outdegrees.head (10))\n",
    "print (\"\\n==> A few entries with small in-degrees:\")\n",
    "display (df_outdegrees.tail ())\n",
    "\n",
    "df_outdegrees_soln = pd.read_csv ('indegrees_soln.csv')\n",
    "assert cse6040utils.tibbles_are_equivalent (df_outdegrees, df_outdegrees_soln)\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** (5 points). Query the database to extract a report of which URLs point to which URLs, storing the result in a Pandas data frame called `df_G`. This data frame should have these columns:\n",
    "\n",
    "- `SourceURL`: URL of a source vertex\n",
    "- `SourceLeaning`: \"Leaning\" value of that vertex\n",
    "- `TargetURL`: URL of the corresponding target vertex\n",
    "- `TargetLeaning`: \"Leaning\" value of that vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3416822d39503a519f6be5248bd1e1c3",
     "grade": false,
     "grade_id": "df_G",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5b0a45fe8f9bca2342841efb33e7c8f2",
     "grade": true,
     "grade_id": "df_G__test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display (df_G.head ())\n",
    "print (\"...\")\n",
    "display (df_G.tail ())\n",
    "\n",
    "df_G_soln = pd.read_csv ('df_G_soln.csv')\n",
    "assert cse6040utils.tibbles_are_equivalent (df_G, df_G_soln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Implement PageRank\n",
    "\n",
    "The following exercises will walk you through a possible implementation of PageRank for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** (5 points). Build a sparse matrix, `PT`, as a Scipy CSR matrix that stores $P^T \\equiv G^TD^{-1}$, where $G^T$ is the transpose of the connectivity matrix $G$, and $D^{-1}$ is the diagonal matrix of inverse out-degrees. Be sure also to do the following:\n",
    "\n",
    "1. Recall that the database indices are 1-based; when converting to the Scipy representation, you should convert these to be 0-based.\n",
    "2. To ensure that there is no \"information loss,\" place a 1.0 at any diagonal entry where there are no outgoing edges.\n",
    "3. Ensure that `PT` is square with dimension `num_vertices`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "954d40349aa7ea6971258d54bd97be5e",
     "grade": false,
     "grade_id": "PT",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "de8f356105e5aa978d6519887a0abdb8",
     "grade": true,
     "grade_id": "PT__test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert PT.shape == (num_vertices, num_vertices)\n",
    "assert len (PT.indices) == 19450\n",
    "\n",
    "# Check that columns sum to 1.0\n",
    "u = np.ones (num_vertices)\n",
    "y_u = np.transpose (PT).dot (u)\n",
    "assert (np.max (np.abs (y_u - u))) <= 3e-15\n",
    "\n",
    "# Check whether `PT` matches what we expect\n",
    "#assert (spio.loadmat ('PT.mat')['PT'] != PT).getnnz () == 0\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9** (10 points). Complete the PageRank implementation for this dataset. To keep it simple, you may take $\\alpha=0.85$, $x(0)$ equal to the vector of all $1/n$ values, and 25 iterations.\n",
    "\n",
    "> **Note.** This implementation asks you to maintain a list, `X`, that stores every `x(t)` that you compute in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "42c297cddce4343d151c143de2e2f18f",
     "grade": false,
     "grade_id": "pagerank",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES BELOW. We've provided some scaffolding code,\n",
    "# so you just need to complete it.\n",
    "\n",
    "ALPHA = 0.85 # Probability of following some link\n",
    "MAX_ITERS = 25\n",
    "n = num_vertices\n",
    "\n",
    "# Let X[t] store the dense vector x(t) at time t\n",
    "X = []\n",
    "\n",
    "x_0 = np.ones (n) / n # Initial distribution: 1/n at each page\n",
    "X.append (x_0)\n",
    "\n",
    "for t in range (1, MAX_ITERS):\n",
    "    # Complete this implementation\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "93cab8393797bc2337496dbfd20212a6",
     "grade": true,
     "grade_id": "pagerank__test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Write some code here to create a table in the database\n",
    "# called PageRank\n",
    "\n",
    "command = '''DROP TABLE IF EXISTS PageRank'''\n",
    "c = conn.cursor ()\n",
    "c.execute (command)\n",
    "\n",
    "command = '''CREATE TABLE PageRank (Id INTEGER, Rank REAL)'''\n",
    "c.execute (command)\n",
    "\n",
    "command = '''INSERT INTO PageRank VALUES (?, ?)'''\n",
    "c.executemany (command, zip (range (1, n+1), X[-1]))\n",
    "\n",
    "# Complete this query:\n",
    "query = '''\n",
    "  SELECT Rank, V.Id, I.Degree AS InDegree, O.Degree AS OutDegree, V.Url, V.Leaning\n",
    "    FROM PageRank AS P, Vertices AS V, Indegrees AS I, Outdegrees AS O\n",
    "    WHERE (P.Id = V.Id) AND (P.Id = I.Id) AND (P.Id = O.Id)\n",
    "    ORDER BY -Rank\n",
    "    LIMIT 10\n",
    "'''\n",
    "df_ranks = pd.read_sql_query (query, conn)\n",
    "display (df_ranks)\n",
    "\n",
    "assert df_ranks['Url'][0] == 'dailykos.com'\n",
    "assert df_ranks['Url'][1] == 'atrios.blogspot.com'\n",
    "assert df_ranks['Url'][2] == 'instapundit.com'\n",
    "assert df_ranks['Url'][3] == 'blogsforbush.com'\n",
    "assert df_ranks['Url'][4] == 'talkingpointsmemo.com'\n",
    "\n",
    "print (\"\\n(Passed.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10** (3 points). The `Vertices` table includes a column called, `Leaning`, which expresses a political leaning -- either \"Left\" or \"Right\". How might you use this column to come up with an alternative ranking scheme?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "c5adb8b69635628ca8759bba9d0ac23e",
     "grade": true,
     "grade_id": "leaning",
     "locked": false,
     "points": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
